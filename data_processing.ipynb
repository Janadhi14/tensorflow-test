{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing data(normalization and standardization)\n",
    "- In terms of scaling values, enural networks tend to prefer normalization \n",
    "- if youre not sure on which to use , you could try both and see which preforms better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf \n",
    "import sklearn \n",
    "\n",
    "# importing the data \n",
    "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to use sklearn to transform out data \n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# now lets create a column transformaer to transform the column \n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), \n",
    "    (OneHotEncoder(handle_unknown = \"ignore\"), [\"sex\", \"smoker\", \"region\"]) # here it is going to one hit encode the values \n",
    "    ) # takes in StandardScalar or MinMaxScalar and OneHotEncoder \n",
    "# we want to tunr all the values in these columns into vlause betwen 0 and on ebecasue they are numerical vlaes, they are not objects of\n",
    "X = insurance.drop(\"charges\" , axis = 1)\n",
    "y = insurance [\"charges\"]\n",
    "# now we want to the model to learn the data and need to split data \n",
    "X_train,X_test, y_train, y_test =train_test_split(X,y, test_size = 0.2, random_state = 42)\n",
    "# fitting the column transformer to our training data \n",
    "ct.fit(X_train) \n",
    "# transform training and test data with automatic with normalization from the training data \n",
    "X_train_normal = ct.transform(X_train)\n",
    "X_test_normal = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60869565, 0.10734463, 0.4       , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.63043478, 0.22491256, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.73913043, 0.23944041, 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.86956522, 0.24791499, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.41304348, 0.85122411, 0.4       , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.80434783, 0.37503363, 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1070, 6), (1070, 11))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 22:53:37.497991: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 13342.6494 - mae: 13342.6494\n",
      "Epoch 2/100\n",
      "25/34 [=====================>........] - ETA: 0s - loss: 13255.9375 - mae: 13255.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 22:53:37.777774: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 13333.4795 - mae: 13333.4795\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13312.0234 - mae: 13312.0234\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13267.7930 - mae: 13267.7930\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13189.5850 - mae: 13189.5850\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13066.4502 - mae: 13066.4502\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12888.1953 - mae: 12888.1953\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12644.6523 - mae: 12644.6523\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12325.5469 - mae: 12325.5469\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11925.9658 - mae: 11925.9658\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11454.3350 - mae: 11454.3350\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10949.8076 - mae: 10949.8076\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10448.9404 - mae: 10448.9404\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9951.6250 - mae: 9951.6250\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9482.7432 - mae: 9482.7432\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9066.7461 - mae: 9066.7461\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8721.9854 - mae: 8721.9854\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8441.2002 - mae: 8441.2002\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8227.5117 - mae: 8227.5117\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8081.9766 - mae: 8081.9766\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7973.8945 - mae: 7973.8945\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7899.1597 - mae: 7899.1597\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7840.3906 - mae: 7840.3906\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7787.9619 - mae: 7787.9619\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7749.2622 - mae: 7749.2622\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7697.9595 - mae: 7697.9595\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7656.0273 - mae: 7656.0273\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7613.4780 - mae: 7613.4780\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7570.9482 - mae: 7570.9482\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7527.4175 - mae: 7527.4175\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7483.5947 - mae: 7483.5947\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7439.4429 - mae: 7439.4429\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7395.0557 - mae: 7395.0557\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7346.8125 - mae: 7346.8125\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7300.0488 - mae: 7300.0488\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7249.8452 - mae: 7249.8452\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7199.5303 - mae: 7199.5303\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7148.4805 - mae: 7148.4805\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7093.6650 - mae: 7093.6650\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7038.1797 - mae: 7038.1797\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6981.7393 - mae: 6981.7393\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6922.7847 - mae: 6922.7847\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6860.1724 - mae: 6860.1724\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6793.7974 - mae: 6793.7974\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6726.6201 - mae: 6726.6201\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6657.4683 - mae: 6657.4683\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6586.3086 - mae: 6586.3086\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6507.5063 - mae: 6507.5063\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6428.6021 - mae: 6428.6021\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6342.7100 - mae: 6342.7100\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6258.0718 - mae: 6258.0718\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6164.7046 - mae: 6164.7046\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6068.6748 - mae: 6068.6748\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5970.0981 - mae: 5970.0981\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5862.5620 - mae: 5862.5620\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5753.9531 - mae: 5753.9531\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5638.0942 - mae: 5638.0942\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5519.8691 - mae: 5519.8691\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5401.3198 - mae: 5401.3198\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5277.3506 - mae: 5277.3506\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5149.7642 - mae: 5149.7642\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5019.3535 - mae: 5019.3535\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4889.6865 - mae: 4889.6865\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4756.8560 - mae: 4756.8560\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4629.4370 - mae: 4629.4370\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4503.5991 - mae: 4503.5991\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4392.9922 - mae: 4392.9922\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4284.3862 - mae: 4284.3862\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4182.6182 - mae: 4182.6182\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4089.5725 - mae: 4089.5725\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4003.3901 - mae: 4003.3901\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3929.0093 - mae: 3929.0093\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3866.3110 - mae: 3866.3110\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3813.7144 - mae: 3813.7144\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3773.0320 - mae: 3773.0320\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3744.1997 - mae: 3744.1997\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3719.6870 - mae: 3719.6870\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3702.9109 - mae: 3702.9109\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3691.8792 - mae: 3691.8792\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3682.8350 - mae: 3682.8350\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3676.9766 - mae: 3676.9766\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3673.9492 - mae: 3673.9492\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3667.8452 - mae: 3667.8452\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3664.5759 - mae: 3664.5759\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3661.8564 - mae: 3661.8564\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3660.3049 - mae: 3660.3049\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3657.5134 - mae: 3657.5134\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3655.2200 - mae: 3655.2200\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3653.8831 - mae: 3653.8831\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3652.0198 - mae: 3652.0198\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3648.9990 - mae: 3648.9990\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3648.4463 - mae: 3648.4463\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3646.2300 - mae: 3646.2300\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3644.4377 - mae: 3644.4377\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3645.8772 - mae: 3645.8772\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3642.2576 - mae: 3642.2576\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3640.1184 - mae: 3640.1184\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3638.0649 - mae: 3638.0649\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3637.2053 - mae: 3637.2053\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3636.1709 - mae: 3636.1709\n"
     ]
    }
   ],
   "source": [
    "# now lets fit a neural model network on the data\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "normal_insurance_model3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100), \n",
    "    tf.keras.layers.Dense(10), \n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "normal_insurance_model3.compile(loss = tf.keras.losses.mae, \n",
    "                                optimizer = tf.keras.optimizers.Adam(),\n",
    "                                metrics = [\"mae\"])\n",
    "with tf.device('/cpu:0'): history2 = normal_insurance_model3.fit(X_train_normal, y_train, epochs=100, verbose=1) # we need to use the with cup or the kernal will crash\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 22:55:01.814301: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 7ms/step - loss: 3438.7844 - mae: 3438.7844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3438.784423828125, 3438.784423828125]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we want to evlauate our model on the normalized data \n",
    "normal_insurance_model3.evaluate(X_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we compare this to the output from the non normalised data ther eis a reduction of 30% in MAE\n",
    "# 9/9 [==============================] - 0s 5ms/step - loss: 4924.4956 - mae: 4924.4956\n",
    "#this was the output from our model 2 with on normalization\n",
    "#done "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1ed3d0d51d0d9fc84e9feca67a2c96385eab8afcf16092b40709d9c6021dc22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
