{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.2\n",
      "1.22.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf   \n",
    "import numpy as np \n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 19:25:31.089771: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-06-25 19:25:31.090099: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating a tensor \n",
    "\n",
    "scalar = tf.constant(7)\n",
    "scalar\n",
    "# testing scalars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the number of dimensions \n",
    "scalar.ndim\n",
    "## this will show 0 becasue there are no dimensions in a scalar with only 1 dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10], dtype=int32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = tf.constant([10,10])\n",
    "vector \n",
    "\n",
    "#here we are making a vector with the 10 ad 10 compoenents then are printing the componenets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the numeber of dimensions that are present in the vector\n",
    "\n",
    "vector.ndim\n",
    "# we are getting 1 as the number of dimensions because we see that there is only 1 dimension in a vector  with 2 compoenents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 7, 10]], dtype=int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = tf.constant([[10,7],\n",
    "                    [7,10]])\n",
    "matrix\n",
    "# creating a tensor matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are now chekcing the number of dimensions\n",
    "matrix.ndim\n",
    "## notice we are getting 2 as the number of dimensions for a matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float16, numpy=\n",
       "array([[10.,  7.],\n",
       "       [ 3.,  2.],\n",
       "       [ 8.,  9.]], dtype=float16)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating another matrix that has datatype defined \n",
    "\n",
    "matrix2 = tf.constant([[10.,7.],\n",
    "                       [3.,2.],\n",
    "                       [8.,9.]], dtype = tf.float16) # specifying the datat type \n",
    "matrix2\n",
    "# initially we are printing out the number of shapes (rows, columns) and tehn the datat type which is float type in this canse )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the numeber of dimensions of our matrix would be still 2 because it is the total number of elements in the shape matrix\n",
    "matrix2.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]],\n",
       "\n",
       "       [[13, 14, 15],\n",
       "        [16, 17, 18]]], dtype=int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## a tensor hads 3 dimensions \n",
    "tensor = tf.constant([[[1,2,3,],[4,5,6]],\n",
    "                      [[7,8,9],[10,11,12]],\n",
    "                      [[13,14,15],[16,17,18]]])\n",
    "tensor\n",
    "#now there is a new element in shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([10,  7], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([10,  7], dtype=int32)>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are able to use tf.variable to create a tensor of the same\n",
    "# we want to create teh same tensor as the tensor above \n",
    "changable_tensor = tf.Variable([10,7])\n",
    "unchangable_tensor = tf.constant([10,7])\n",
    "changable_tensor,unchangable_tensor\n",
    "#the output will be the same but the variable will be 0 in the changalbe tensor because we are able to change the variable  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([7, 7], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to change the element in the 0th posisiton \n",
    "# then we can use the .assign() function to change the value \n",
    "changable_tensor[0].assign(7)\n",
    "changable_tensor\n",
    "\n",
    "# now we have changed the value so the tensor reads [7,7]\n",
    "# we are not able to change the values in the constant tensors \n",
    "#generally we want to use constant tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[-1.3240396 ,  0.28785667],\n",
       "       [-0.8757901 , -0.08857018],\n",
       "       [ 0.69211644,  0.84215707]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating random tensors \n",
    "# these are tensors tensors that are of abitrary size which contain random numbers \n",
    "# this might be done in the scenario of a neural netowrk it will initilize a neurla network with random number s and then as it learns it will change the random tensors in order to change the weightings \n",
    "with tf.device('/cpu:0'): randomtensor1 = tf.random.Generator.from_seed(7) # the seed for reproducibility \n",
    "randomtensor1 = randomtensor1.normal(shape=(3, 2))\n",
    "randomtensor1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[-1.3240396 ,  0.28785667],\n",
       "       [-0.8757901 , -0.08857018],\n",
       "       [ 0.69211644,  0.84215707]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.device('/cpu:0'): randomtensor2 = tf.random.Generator.from_seed(7)\n",
    "randomtensor2 = randomtensor2.normal(shape=(3,2)) # generates numbers fomr a normal distribution\n",
    "randomtensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
       "array([[ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True]])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomtensor1 == randomtensor2\n",
    "# now we are chekcing if 2 different tensors are equal \n",
    "# we can use the == operater to check this \n",
    "#wehn we set the seed we essetially modify the random numbers with the certain seed \n",
    "#if we change teh seed we will get different value \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to shuffle the order of teh elements in a tensor\n",
    "# shuffle tensor so that the inherent order doesnt affect the tensor \n",
    "not_shuffled = tf.constant([[10,7],\n",
    "                            [3,4],\n",
    "                            [8,9]],)\n",
    "not_shuffled.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 8,  9]], dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 8,  9],\n",
       "       [ 3,  4]], dtype=int32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)# the operation level seed #now if we set the seed first and then we are going to affect the behaviour of the tensor so ts certain \n",
    "shuffled = tf.random.shuffle(not_shuffled, seed = 3) #this contains the operation level seed\n",
    "shuffled\n",
    "# shuffling the tensor along the first dimension\n",
    "#what if we want to shuffle along the second dimension ?\n",
    "# what happens when we shuffle seeds is that we are going to \n",
    "# if both the global and operation level seeds are set then theya re used in conjucntion \n",
    "# if we want our shuffled tensors we have to use the global level random seed \n",
    "# to make reproducable experiments we may use random seeds and set them to enable reproducable randomness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 4), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numpy ones is a way to make tensors \n",
    "# we are able to use the tf.ones method to create a tensor that consisitas of all float type ones \n",
    "tf.ones([10,4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros(shape = (3,4)) # passing in the shape as the rows adn columnsof the array that we want \n",
    "#very simialr to numpy so we are able to convert numpy arrays into tensorflow tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing numpy and then coverting numpy arrays into tensorflow tensors \n",
    "import numpy as np\n",
    "numpy_A = np.arange(1,25, dtype = np.int32) # create a Numpy array between 1 and 25 and we need to define the data type which is integer of typ 32 \n",
    "numpy_A # arrays are often noted with capital letters \n",
    "\n",
    "# X = tf.constant(some_matrix) # capital for matrix or tensor \n",
    "# y = tf.constnat(vector) # non-capital for vector \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24], dtype=int32)>,\n",
       " <tf.Tensor: shape=(3, 8), dtype=int32, numpy=\n",
       " array([[ 1,  2,  3,  4,  5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12, 13, 14, 15, 16],\n",
       "        [17, 18, 19, 20, 21, 22, 23, 24]], dtype=int32)>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we want to convert numpy arrays into tenors\n",
    "# the main difference between these two is that tensors can be run on a GPU much faster \n",
    "A = tf.constant(numpy_A)# we are converting it to a different shape\n",
    "B = tf.constant(numpy_A, shape = (3,8))\n",
    "A, B\n",
    "# anyhitng iwth a numpy we are able to pass into a tensor function\n",
    "# we can only select elements that are supported so the values in teh tensor shaoe argunent in constant needs specific shape values for paticular arrangement \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=24>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.size(A)\n",
    "tf.size(B)\n",
    "#this is chekcing the total number of items in a tensor\n",
    "#the numpy output is the size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a rank 4 tensor\n",
    "rand_4_tensor = tf.zeros(shape = [2,3,4,5])\n",
    "rand_4_tensor\n",
    "#creating a tensor that consisits of all zeros that contains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4, 5), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_4_tensor[0]\n",
    "#getting the 0th element of the tensor   \n",
    "#notice the tensor changes becasue we are gettinh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3, 4, 5]), 4, <tf.Tensor: shape=(), dtype=int32, numpy=120>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_4_tensor.shape,rand_4_tensor.ndim, tf.size(rand_4_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dimensions(rank): 4\n",
      "shape of tensor: (2, 3, 4, 5)\n",
      "number of elememts along the 0 axis: 2\n",
      "number of elements along the 1st axis: 5\n",
      "total number of elements in out tensor: tf.Tensor(120, shape=(), dtype=int32)\n",
      "total number of elements in out tensor: 120\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"number of dimensions(rank):\", rand_4_tensor.ndim)\n",
    "print(\"shape of tensor:\", rand_4_tensor.shape)\n",
    "print(\"number of elememts along the 0 axis:\", rand_4_tensor.shape[0])\n",
    "print(\"number of elements along the 1st axis:\", rand_4_tensor.shape[-1])\n",
    "print(\"total number of elements in out tensor:\", tf.size(rand_4_tensor))\n",
    "print(\"total number of elements in out tensor:\", tf.size(rand_4_tensor).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 21]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list = [2,21,12,3]\n",
    "some_list[:2]\n",
    "# here we have an array and we want to get the fisrt 2 items of that array we use the :n function and use 2 as n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2, 2), dtype=float32, numpy=\n",
       "array([[[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#indexing tensors \n",
    "#tensors can be indexed just like python lists \n",
    "#if we want to get the first 2 element \n",
    "rand_4_tensor[:2,:2,:2,:2]\n",
    "# here we are getting the first 2 items of every tensor array \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the first element form each dimension from each index except for the final one and\n",
    "rand_4_tensor[:1, :1, :1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 2]), 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets add an extra dimensison\n",
    "#create a rank 2 tensor \n",
    "rank_2_tensor = tf.constant([[2,2],\n",
    "                            [3,4]])\n",
    "rank_2_tensor.shape, rank_2_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[2],\n",
       "        [2]],\n",
       "\n",
       "       [[3],\n",
       "        [4]]], dtype=int32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#addin in an extra dimension ot out rank 2 tensor \n",
    "rand_3_tensor = rank_2_tensor[...,tf.newaxis] #instead of doing [:,:,:, tf.newaxis] we can use the term [...] for the previous axies \n",
    "rand_3_tensor \n",
    "\n",
    "#tf.newaxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[2],\n",
       "        [2]],\n",
       "\n",
       "       [[3],\n",
       "        [4]]], dtype=int32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alternative to tf.newaxis \n",
    "tf.expand_dims(rank_2_tensor, axis = -1) \n",
    "\n",
    "# this means we are expanding along the final axis which is refered to by -1 which is the last axis \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[2, 2],\n",
       "       [3, 4]], dtype=int32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(rank_2_tensor, axis = 0) \n",
    "#if we get an expansion of the 0th axis we are going to get a differnet expansions \n",
    "rank_2_tensor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[20, 17],\n",
       "       [13, 14]], dtype=int32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##manipulating tensors (tensor operations)\n",
    "#you can add caues to a tensor isong teh addition operator\n",
    "tensor = tf.constant([[10,7], \n",
    "                      [3,4]])\n",
    "tensor + 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[20, 17],\n",
       "       [13, 14]], dtype=int32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#notice that the origional tensor is unchanged \n",
    "# if we say taht:\n",
    "tensor = tensor+ 10 \n",
    "tensor\n",
    "#this will reuslt in the tensors values being rewritten \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[23, 20],\n",
       "       [16, 17]], dtype=int32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#element operations \n",
    "# we are able to use tensorflow builtin functions to carry out the same examples \n",
    "tf.multiply(tensor, 10) # where the alias is the multiply \n",
    "#if we use the tf. ..... versions of the function we will be able to spped up operations raother than coding out tensor*10\n",
    "tf.add(tensor, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[621, 578],\n",
       "       [442, 417]], dtype=int32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix multiplications are one of teh omst common operations \n",
    "#matrix multiplication is when you are multiplying matricies \n",
    "#to multiply tensors we need to do the dot product \n",
    "#this is where we multiply matching members \n",
    "tf.matmul(tensor, tensor) # we dont need the full \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[20, 59],\n",
       "       [34, 57],\n",
       "       [30, 60]], dtype=int32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given a certain matrix recreate in TF\n",
    "tensor_A = tf.constant([[1,2,5], \n",
    "                        [7,2,1], \n",
    "                        [3,3,3]])\n",
    "tensor_B = tf.constant([[3,5],\n",
    "                        [6,7],\n",
    "                        [1,8]])\n",
    "tf.matmul(tensor_A, tensor_B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[621, 578],\n",
       "       [442, 417]], dtype=int32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we wanted to do matrix multiplication with a python operator \n",
    "tensor @ tensor # the @ symbolos for matrix multiplication in python \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Matrix size-incompatible: In[0]: [3,2], In[1]: [3,2] [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/janadhi/tensorflow-test/testing1.ipynb Cell 45'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janadhi/tensorflow-test/testing1.ipynb#ch0000044?line=1'>2</a>\u001b[0m tensor_C \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant([[\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janadhi/tensorflow-test/testing1.ipynb#ch0000044?line=2'>3</a>\u001b[0m                         [\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janadhi/tensorflow-test/testing1.ipynb#ch0000044?line=3'>4</a>\u001b[0m                         [\u001b[39m5\u001b[39m,\u001b[39m6\u001b[39m]])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janadhi/tensorflow-test/testing1.ipynb#ch0000044?line=4'>5</a>\u001b[0m tensor_D \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant([[\u001b[39m7\u001b[39m,\u001b[39m8\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janadhi/tensorflow-test/testing1.ipynb#ch0000044?line=5'>6</a>\u001b[0m                         [\u001b[39m9\u001b[39m,\u001b[39m10\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/janadhi/tensorflow-test/testing1.ipynb#ch0000044?line=6'>7</a>\u001b[0m                         [\u001b[39m11\u001b[39m,\u001b[39m12\u001b[39m]])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/janadhi/tensorflow-test/testing1.ipynb#ch0000044?line=7'>8</a>\u001b[0m tf\u001b[39m.\u001b[39;49mmatmul(tensor_C, tensor_D)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7163\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7164\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [3,2], In[1]: [3,2] [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "# create 2 tensors with different shapes and multiply them  \n",
    "tensor_C = tf.constant([[1,2],\n",
    "                        [3,4],\n",
    "                        [5,6]])\n",
    "tensor_D = tf.constant([[7,8],\n",
    "                        [9,10],\n",
    "                        [11,12]])\n",
    "tf.matmul(tensor_C, tensor_D)\n",
    "\n",
    "# we are going to get the error \"Matrix size-incompatible: In[0]: [3,2], In[1]: [3,2] [Op:MatMul]\"\"\n",
    "# we can't do this because thre ar erules that matrix and tensors need to follow \n",
    "# there are 2 rules that need to be fufilled in order to be complete the muliplication\n",
    "# 1) the inner dimensions must match\n",
    "# 2) the resulting matrix has the shape of the outer dimensions\n",
    "# how can we get the immer dimensions to match?\n",
    "# we can rearrange the matrix?\n",
    "# we need to change the shape of one of the matricies \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[ 7,  8,  9],\n",
       "       [10, 11, 12]], dtype=int32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tensor_reshaped_D = tf.reshape(tensor_D, shape=(2,3)) # we are changing the shaep of the matrix so that it is now 2,3 \n",
    "# now we taking tensor 2 and changing it from a 3, 2 to a 2, 3 tensor \n",
    "# now notice that the tensor is in 2, 3 shape and this will enable us to multiply array C by array D \n",
    "\n",
    "tensor_reshaped_D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 27,  30,  33],\n",
       "       [ 61,  68,  75],\n",
       "       [ 95, 106, 117]], dtype=int32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are multiplying c by reshaped D  becasue now the inner dimensiosn match now becase they are both 2\n",
    "tensor_C @ tensor_reshaped_D\n",
    "#umltiplied the matrices using the python method  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 76, 100],\n",
       "       [103, 136]], dtype=int32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we are multiplying the arrays C and D \n",
    "tf.matmul(tensor_reshaped_D,tensor_C)\n",
    "# remember that the resulting  output is dependent on the manipulation of what ever matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 2, 3],\n",
       "        [4, 5, 6]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 3, 5],\n",
       "        [2, 4, 6]], dtype=int32)>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose is another useful tensor function which is slightly different to a tensor function\n",
    "tensor_C, tf.reshape(tensor_C, shape = (2,3)),tf.transpose(tensor_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]], dtype=int32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ry matrix multiplication with transpose rather than reshape \n",
    "tf.matmul(tf.transpose(tensor_C), tensor_D)\n",
    "# the output is different eto the previous reshaped C matrix multiplication with tensor_D because transposition causes the reshaping of the axies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** the dot product **    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]], dtype=int32)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to preform the dot product on the tensor_C and tensor_Y requires C and D to be tranposed\n",
    "tf.tensordot(tf.transpose(tensor_C), tensor_D, axes = 1) # we are changingn along the first axis \n",
    "# tf.tensordot(thensor contraction of products within the argument along a paticular axes )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 23,  29,  35],\n",
       "       [ 53,  67,  81],\n",
       "       [ 83, 105, 127]], dtype=int32)>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to tranpose along D and reshape D\n",
    "tf.matmul(tensor_C, tf.transpose(tensor_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 27,  30,  33],\n",
       "       [ 61,  68,  75],\n",
       "       [ 95, 106, 117]], dtype=int32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we want to preform mutiplicatio between tensor _C and tensor_D(reshaped)\n",
    "tf.matmul(tensor_C, tf.reshape(tensor_D, shape = (2, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notice that we are getting different results between transpose and reshape functions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal tensor_D:\n",
      "tf.Tensor(\n",
      "[[ 7  8]\n",
      " [ 9 10]\n",
      " [11 12]], shape=(3, 2), dtype=int32) \n",
      "\n",
      "tensor_D reshaped to (2,3):\n",
      "tf.Tensor(\n",
      "[[ 7  8  9]\n",
      " [10 11 12]], shape=(2, 3), dtype=int32) \n",
      "\n",
      "tensor_D transposed:\n",
      "tf.Tensor(\n",
      "[[ 7  9 11]\n",
      " [ 8 10 12]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\"normal tensor_D:\")\n",
    "print(tensor_D, \"\\n\")\n",
    "\n",
    "print(\"tensor_D reshaped to (2,3):\")\n",
    "print(tf.reshape((tensor_D), shape = (2,3)),  \"\\n\")\n",
    "\n",
    "print(\"tensor_D transposed:\")\n",
    "print(tf.transpose(tensor_D))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 23,  29,  35],\n",
       "       [ 53,  67,  81],\n",
       "       [ 83, 105, 127]], dtype=int32)>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(tensor_C, tf.transpose(tensor_D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " generally when preforming matrix multimplication on 2 axies and when teh axies dont lig up will will transpose one of the matricies to satiesfy the rules and then multiply the tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we have to change the data type of a tensor \n",
    "# the default data type of most tensors are int 32 \n",
    "# create a new tensor with a default datatype (float32)\n",
    "\n",
    "B = tf.constant([1.3,1.4])\n",
    "B.dtype \n",
    "\n",
    "# the default datat type will depend on the type of data in the tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int32"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = tf.constant([34,223,32])\n",
    "C.dtype\n",
    "# notice that there is a different data type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2,), dtype=float16, numpy=array([1.3, 1.4], dtype=float16)>,\n",
       " tf.float16)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we want to change from type 32 to 16 data type then this is called reduced precision \n",
    "# this is when there is lower precision but same accuracy \n",
    "D = tf.cast(B, dtype = tf.float16)\n",
    "D, D.dtype\n",
    "# now we are getting faster processing because we are using less memory (half as much)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.2998047, 1.4003906], dtype=float32)>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now if we want to change from float 16 to float 32\n",
    "E = tf.cast(D, dtype = tf.float32)\n",
    "E\n",
    "# now we are getting a float 32 type data type "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregating tensors \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 7, 10], dtype=int32)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aggregating tensors requires the condensing the tensors from multiple values down to a smaller amount of values\n",
    "# get the absolute calues condensing\n",
    "D = tf.constant([-7,-10])\n",
    "D \n",
    "#if we want to get the absolute values we use the tf.abs(tensorname)\n",
    "tf.abs(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets go through the following forms of aggregation \n",
    "- getting the maxium\n",
    "- getting the minimum\n",
    "- getting the sum \n",
    "- getting the mean \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=-8>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the mean of a tensor we use the function tf.reduce_mean()\n",
    "tf.reduce_mean(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
       "array([59, 76, 88, 58, 93, 24, 16, 53, 79, 92, 69, 86, 31, 52, 67, 63,  9,\n",
       "       62, 72, 38, 36, 22, 86,  6, 58, 60, 17, 49, 88, 21, 51, 49, 77, 22,\n",
       "       88, 45, 24, 26,  6, 70, 98, 30, 40, 76,  4, 68, 33, 13, 91,  6])>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets create a new tensor \n",
    "F = tf.constant(np.random.randint(0,100,size = 50))\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int64, numpy=4>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=98>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=2547>,\n",
       " <tf.Tensor: shape=(), dtype=int64, numpy=50>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(F),tf.reduce_max(F), tf.reduce_sum(F), tf.reduce_mean(F),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to find the varience and the standard deviation in a tensor?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=27.308725>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in order to use the varience function we need to import tensorflow probability \n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfp.stats.variance(F)\n",
    "tf.math.reduce_std(tf.cast(F, dtype = tf.float32))\n",
    "                   # notice that to get the standard deviation we need to cast the tensor to float32 type \n",
    "#there is another way to get the varience \n",
    "tf.math.reduce_variance(tf.cast(F, dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the positional maximum and minimum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
       "array([0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
       "       0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
       "       0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
       "       0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
       "       0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
       "       0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
       "       0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
       "       0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
       "       0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
       "       0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "with tf.device('/cpu:0'): G = tf.random.uniform(shape=[50])\n",
    "G \n",
    "# we need to run the function in the tf.device \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=42>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find the postiional maximum \n",
    "tf.argmax(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.9671384>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we are indexing on our largest value \n",
    "G[tf.argmax(G)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.9671384>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# findignn the max vlue of G \n",
    "tf.reduce_max(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for eqality indexing\n",
    "G[tf.argmax(G)] == tf.reduce_max(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=16>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the positional minimum \n",
    "tf.argmin(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.009463668>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we want to get the index \n",
    "G[tf.argmin(G)]\n",
    "# this will return the value at that index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need to find the minimum using the positional minimum index\n",
    "G[tf.argmin(G)] == tf.reduce_min(G)\n",
    "\n",
    "# this returns true which will validate that there is a minimum at this positon because the tf.reduce_min will return the minimum and we are comparieng both and will return true if they are the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1ed3d0d51d0d9fc84e9feca67a2c96385eab8afcf16092b40709d9c6021dc22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
