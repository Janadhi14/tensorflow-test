{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to regression with neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import sklearn as sk\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what are regression problems?\n",
    "- this generally involves predicting numbers \n",
    "- generally predicting\n",
    "- in a neural network regression we are generally going to be modeling and predicting teh relationships bewteent eh dependent vaiables and independent variables (set number (data)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we generally need inputs and outputs \n",
    "the input will be the independent variables that are known  \n",
    "we need to  encode the independent variabbles into a neumerically encoded tensor\n",
    "- often an algorithms that we feed the input data into is gnenrally already made \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x29596ca90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first we will create the featuers \n",
    "X = np.array([-7.0, - 4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
    "# creating lables (dependent variables)\n",
    "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "# visualisation of this data isiong a scatter plot\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  6.,  9., 12., 15., 18., 21., 24.]),\n",
       " array([ True,  True,  True,  True,  True,  True,  True,  True]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the relationship seen :\n",
    "X + 10, y== X+10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input and output shapes of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets create a demo tensor for out housing problem \n",
    "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
    "house_price = tf.constant([939700])\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notice the input shape is 3 and the output shape is 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8,), (8,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X.shape\n",
    "output_shape = y.shape\n",
    "\n",
    "input_shape, output_shape \n",
    "# notice that the output is 8 and 8 because there are correlated with 8 differnet inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.0, 3.0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]\n",
    "# notcie that we are using X 0 to preduct Y 0 \n",
    "#so we want to use one input feature to predct one output feature \n",
    "# we want to build a model that takes one X value to predicting one y value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets turn out numpy arrays into tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.cast(tf.constant(X), dtype = tf.float32)\n",
    "y = tf.cast(tf.constant(y), dtype = tf.float32)\n",
    "\n",
    "X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x29573fa60>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps in modeling \n",
    "- creating a model where we are defining the nput, output and hidden laters of a deep earning model \n",
    "- copiling  amodel and deifning the loss function(a function that tells out model how wrong out model is )\n",
    "- the optimizer(tells out model how to improve our pattern)\n",
    "- fitting a model- letting the model try and dind patterns between X and y (features and lables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 14:28:30.223525: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# first we need to set the seed \n",
    "X = tf.cast(tf.constant(X), dtype = tf.float32)\n",
    "y = tf.cast(tf.constant(y), dtype = tf.float32)\n",
    "\n",
    "X, y\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "# lets create a model using teh sequenctial API\n",
    "model= tf.keras.Sequential([ #groups a linear stack of layers into a tf.keras.Model.\n",
    "    tf.keras.layers.Dense(1)\n",
    "    ]) # this is basically saying that we want to generate a model from keras \n",
    "# now we want to compule the model \n",
    "model.compile(loss=tf.keras.losses.mae, # mae measn mean abouslue error, which is a measure of error between paired observations expressing the same phenomenon, compairson between preducted vs observed  )- \n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "# now we want to fit the model \n",
    "with tf.device('/cpu:0'): model.fit(tf.expand_dims(X, axis=-1), y, epochs=5) # we need to use the with cup or the kernal will crash\n",
    "# epochs refers to the number of runs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the tf.keras.losses.MAE function is beased on teh application of the loss function withwhich easure sthe mean (abs(y_true  -y_pred), axis = -1).\n",
    "we are calculating teh differnce bteween teh f=true value and the preducted value and getting the absoliuete value of themse 2 and generating a mean of that laong a specifc axis\n",
    "on average how wrong are our preductions \n",
    "SGD - this is stochastic gradient descent which is used to optimize, so that we are using stochastic approximation for gradient descent optimization and generates preductive vlues to fill in data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are multiple ways to add layers to our model in tensorflow\n",
    "we are able to use either:\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1), \n",
    "])\n",
    "\n",
    "or we can use the term:\n",
    "model .add(tf.keras.layers.Dense(1)) where 1 is the number of layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 14:28:30.344098: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[12.716021]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we want to try and predict using using the model \n",
    "y_pred = model.predict([17.0])\n",
    "y_pred\n",
    "# our model realizes that there is a differnce of about + 11 in the y values so thus it is going to predict an addition of about 12 but this isnt quite accurate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to improve the model we need to:\n",
    "- by adding more layers to the\n",
    "- within each of teh hidden laeer we can change the actiavtion function of each layer \n",
    "- we could change the ptimization function or the lernaing rate of the optimization function\n",
    "- when we are fitting the model we might increase the number of epochs which will allow the model to run more examples to learn from.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tensorflow ther ear e2 differnet models we are able to use for generating predictions\n",
    "- the smaller models use the SGD where as the larger models have more layers \n",
    "- the number of neurons in each layer is increased in larger models \n",
    "- larger models also use the Adam optimizer with an lr (learning rate) the higher the learning rate the more that the optimizer is pushig the model to learn, the lower the learning rate, teh smaller the steps the optimizer tells the model to take to improve \n",
    "- there is also a differnce in the subset in the smaller model but in the larger model uses X_train_full and y_train_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 14:28:30.534899: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 143ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9748 - mae: 10.9748\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.8423 - mae: 10.8423\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7098 - mae: 10.7098\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5773 - mae: 10.5773\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.4448 - mae: 10.4448\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.3123 - mae: 10.3123\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1798 - mae: 10.1798\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.0473 - mae: 10.0473\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9148 - mae: 9.9148\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.7823 - mae: 9.7823\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.6498 - mae: 9.6498\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.5173 - mae: 9.5173\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.3848 - mae: 9.3848\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2523 - mae: 9.2523\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.1198 - mae: 9.1198\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.9873 - mae: 8.9873\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8548 - mae: 8.8548\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.7223 - mae: 8.7223\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.5898 - mae: 8.5898\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.4573 - mae: 8.4573\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.3248 - mae: 8.3248\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.1923 - mae: 8.1923\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.0598 - mae: 8.0598\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.9273 - mae: 7.9273\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.7948 - mae: 7.7948\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6623 - mae: 7.6623\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.5298 - mae: 7.5298\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.3973 - mae: 7.3973\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.2648 - mae: 7.2648\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2525 - mae: 7.2525\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2469 - mae: 7.2469\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2413 - mae: 7.2413\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2356 - mae: 7.2356\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2300 - mae: 7.2300\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2244 - mae: 7.2244\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2188 - mae: 7.2188\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2131 - mae: 7.2131\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2075 - mae: 7.2075\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2019 - mae: 7.2019\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1963 - mae: 7.1963\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1906 - mae: 7.1906\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1850 - mae: 7.1850\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1794 - mae: 7.1794\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1738 - mae: 7.1738\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1681 - mae: 7.1681\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1625 - mae: 7.1625\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1569 - mae: 7.1569\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1512 - mae: 7.1512\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1400 - mae: 7.1400\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1344 - mae: 7.1344\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1287 - mae: 7.1287\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1231 - mae: 7.1231\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1175 - mae: 7.1175\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1119 - mae: 7.1119\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1063 - mae: 7.1063\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1006 - mae: 7.1006\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0894 - mae: 7.0894\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0837 - mae: 7.0837\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0781 - mae: 7.0781\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0725 - mae: 7.0725\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0669 - mae: 7.0669\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0613 - mae: 7.0613\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0556 - mae: 7.0556\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0500 - mae: 7.0500\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0444 - mae: 7.0444\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0388 - mae: 7.0388\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0331 - mae: 7.0331\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0275 - mae: 7.0275\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0219 - mae: 7.0219\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0163 - mae: 7.0163\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0106 - mae: 7.0106\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0050 - mae: 7.0050\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9994 - mae: 6.9994\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9938 - mae: 6.9938\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9825 - mae: 6.9825\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9769 - mae: 6.9769\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9656 - mae: 6.9656\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9600 - mae: 6.9600\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9544 - mae: 6.9544\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9488 - mae: 6.9488\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9431 - mae: 6.9431\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9375 - mae: 6.9375\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9319 - mae: 6.9319\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9263 - mae: 6.9263\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9206 - mae: 6.9206\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9150 - mae: 6.9150\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9094 - mae: 6.9094\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9038 - mae: 6.9038\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8981 - mae: 6.8981\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8925 - mae: 6.8925\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8869 - mae: 6.8869\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8813 - mae: 6.8813\n"
     ]
    }
   ],
   "source": [
    "# lets see if we can increase our current model by increaseing teh epochs to 100 \n",
    "tf.random.set_seed(42)\n",
    "# lets create a model using teh sequenctial API\n",
    "model= tf.keras.Sequential([ #groups a linear stack of layers into a tf.keras.Model.\n",
    "    tf.keras.layers.Dense(1)\n",
    "    ]) # this is basically saying that we want to generate a model from keras \n",
    "# now we want to compule the model \n",
    "model.compile(loss=tf.keras.losses.mae, # mae measn mean abouslue error, which is a measure of error between paired observations expressing the same phenomenon, compairson between preducted vs observed  )- \n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "# now we want to fit the model \n",
    "with tf.device('/cpu:0'): model.fit(tf.expand_dims(X, axis=-1), y, epochs=100) # we need to use the with cup or the kernal will crash\n",
    "# epochs refers to the number of runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 14:28:31.142259: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[30.158512]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets predict again to see if the prediction has improved \n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets try and reqrite the code so that we are going to optimize with the addition of more code that will help improve the accuracy of the preduction\n",
    "- lets try and add another layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 14:28:31.326475: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 142ms/step - loss: 12.9775 - mae: 12.9775\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.9112 - mae: 12.9112\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.8450 - mae: 12.8450\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.7787 - mae: 12.7787\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.7125 - mae: 12.7125\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.6462 - mae: 12.6462\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.5800 - mae: 12.5800\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.5137 - mae: 12.5137\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.4475 - mae: 12.4475\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.3812 - mae: 12.3812\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.3150 - mae: 12.3150\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.2487 - mae: 12.2487\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.1825 - mae: 12.1825\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.1162 - mae: 12.1162\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.0500 - mae: 12.0500\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.9837 - mae: 11.9837\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.9175 - mae: 11.9175\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.8512 - mae: 11.8512\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.7850 - mae: 11.7850\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.7187 - mae: 11.7187\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.6525 - mae: 11.6525\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.5862 - mae: 11.5862\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.5200 - mae: 11.5200\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.4537 - mae: 11.4537\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.3875 - mae: 11.3875\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.3212 - mae: 11.3212\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2550 - mae: 11.2550\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1887 - mae: 11.1887\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1225 - mae: 11.1225\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.0562 - mae: 11.0562\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9900 - mae: 10.9900\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9237 - mae: 10.9237\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.8575 - mae: 10.8575\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7912 - mae: 10.7912\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7250 - mae: 10.7250\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.6587 - mae: 10.6587\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5925 - mae: 10.5925\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5262 - mae: 10.5262\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.4600 - mae: 10.4600\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.3937 - mae: 10.3937\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.3275 - mae: 10.3275\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.2612 - mae: 10.2612\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1950 - mae: 10.1950\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1287 - mae: 10.1287\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.0625 - mae: 10.0625\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9962 - mae: 9.9962\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9300 - mae: 9.9300\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.8637 - mae: 9.8637\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.7975 - mae: 9.7975\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.7312 - mae: 9.7312\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.6650 - mae: 9.6650\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.5987 - mae: 9.5987\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.5325 - mae: 9.5325\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.4662 - mae: 9.4662\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.4000 - mae: 9.4000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.3337 - mae: 9.3337\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2675 - mae: 9.2675\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2012 - mae: 9.2012\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.1350 - mae: 9.1350\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.0687 - mae: 9.0687\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0025 - mae: 9.0025\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.9362 - mae: 8.9362\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8700 - mae: 8.8700\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8037 - mae: 8.8037\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.7375 - mae: 8.7375\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6712 - mae: 8.6712\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.6050 - mae: 8.6050\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.5387 - mae: 8.5387\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.4725 - mae: 8.4725\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.4062 - mae: 8.4062\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3420 - mae: 8.3420\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3075 - mae: 8.3075\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.2729 - mae: 8.2729\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.2384 - mae: 8.2384\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.2039 - mae: 8.2039\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.1693 - mae: 8.1693\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.1348 - mae: 8.1348\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.1003 - mae: 8.1003\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.0658 - mae: 8.0658\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.0312 - mae: 8.0312\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.9967 - mae: 7.9967\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.9622 - mae: 7.9622\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.9276 - mae: 7.9276\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.8931 - mae: 7.8931\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.8586 - mae: 7.8586\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.8240 - mae: 7.8240\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.7895 - mae: 7.7895\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7550 - mae: 7.7550\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7204 - mae: 7.7204\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.6859 - mae: 7.6859\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.6514 - mae: 7.6514\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6168 - mae: 7.6168\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.5823 - mae: 7.5823\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.5478 - mae: 7.5478\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.5133 - mae: 7.5133\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.4787 - mae: 7.4787\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4442 - mae: 7.4442\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4097 - mae: 7.4097\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.3751 - mae: 7.3751\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.3406 - mae: 7.3406\n"
     ]
    }
   ],
   "source": [
    "# lets see if we can increase our current model by increaseing teh epochs to 100 \n",
    "tf.random.set_seed(42)\n",
    "# lets create a model using teh sequenctial API\n",
    "model= tf.keras.Sequential([ #groups a linear stack of layers into a tf.keras.Model.\n",
    "    tf.keras.layers.Dense(2) # now we have 2 hidden layers of neurons \n",
    "    ]) # this is basically saying that we want to generate a model from keras \n",
    "# now we want to compule the model \n",
    "model.compile(loss=tf.keras.losses.mae, # mae measn mean abouslue error, which is a measure of error between paired observations expressing the same phenomenon, compairson between preducted vs observed  )- \n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "# now we want to fit the model \n",
    "with tf.device('/cpu:0'): model.fit(tf.expand_dims(X, axis=-1), y, epochs=100) # we need to use the with cup or the kernal will crash\n",
    "# epochs refers to the number of runs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a model \n",
    "in practice a typical workflow youll go through when building neural networks:\n",
    "- build a model\n",
    "- fit it \n",
    "- evaluate it \n",
    "- tweak a model \n",
    "- fit it \n",
    "- evaluate it ... and repeate until we have met the desired outcome :)\n",
    "\n",
    "when it comes to evaluation of out models we want to visualise our output with the desired output.\n",
    "Generally we want to plot our data. this can go into the optimization of hyperparameters so that the predictions are as accurate across different input parameters for X\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96], dtype=int32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets make a bigger data set \n",
    "X = tf.range(-100,100,4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets make labes for the data set \n",
    "# we watnt eh pattern to learn this relationship that y = X +10\n",
    "y = X+10\n",
    "y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x295cbed60>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now we want to visualise the data \n",
    "import matplotlib.pyplot as plt   \n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we visualise the training of the data we need to look into the theory of the 3 sets \n",
    "# the 3 sets refers to brekaing up the data into 3 differnet sets (training set, validation set, test set)\n",
    "# you generally have a training set of data (70-80% of the data we have avalible ) - this is where we would tweak the model\n",
    "# the vaidation set- is wher ewe are going to  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 sets theory \n",
    "- Generally in machine learning we have 3 sets of data that we utilise in the model\n",
    "- a training set where the model learns from this data which accounts for about 70-80% if teh ttal data you have avalible \n",
    "- a validation set -  the model gets tuned on this data, which is typically 10-15% of the data avalible\n",
    "- there is also the test set which is typically 10-15% of the total data avalible  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the length of how many samples we have \n",
    "len(X)\n",
    "# we shoul d genrally have a minimum of 100 in general for deep learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets split the data into training and test sets  \n",
    "X_train  = X [:40] # this is 80% of the data \n",
    "X_test = X[40:] # this is the last 10\n",
    " \n",
    "y_train = y[:40] # this is the first 40 that are dedicated to learning \n",
    "y_test = y [40:] # this the test set that contains teh last 10 values of the data set\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now we want to visualise the data in the test sets \n",
    "plt.figure(figsize = (5,4)) # setting the figure size \n",
    "# we wnat to plot the training data in blue\n",
    "\n",
    "plt.scatter(X_train, y_train, c= \"b\", label = \"train data \") #plotting the training data in blue \n",
    "plt.scatter(X_test, y_test, c= \"g\", label= \"test data \") #plotting the test data in green\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets generate a model that is able to predict \n",
    "# lets see if we can increase our current model by increaseing teh epochs to 100 \n",
    "tf.random.set_seed(42)\n",
    "# lets create a model using teh sequenctial API\n",
    "model= tf.keras.Sequential([ #groups a linear stack of layers into a tf.keras.Model.\n",
    "    tf.keras.layers.Dense(1)# now we have 2 hidden layers of neurons \n",
    "    ]) # this is basically saying that we want to generate a model from keras \n",
    "# now we want to compule the model \n",
    "model.compile(loss=tf.keras.losses.mae, # mae measn mean abouslue error, which is a measure of error between paired observations expressing the same phenomenon, compairson between preducted vs observed  )- \n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "# now we want to fit the model \n",
    "#with tf.device('/cpu:0'): model.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100) # we need to use the with cup or the kernal will crash\n",
    "# epochs refers to the number of runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets generate a model that is able to predict \n",
    "# lets see if we can increase our current model by increaseing teh epochs to 100 \n",
    "tf.random.set_seed(42)\n",
    "# lets create a model using teh sequenctial API\n",
    "with tf.device('/cpu:0'): model= tf.keras.Sequential([ #groups a linear stack of layers into a tf.keras.Model.\n",
    "    tf.keras.layers.Dense(1, input_shape = [1])# now we have 2 hidden layers of neurons \n",
    "    ]) # this is basically saying that we want to generate a model from keras \n",
    "# now we want to compule the model \n",
    "model.compile(loss=tf.keras.losses.mae, # mae measn mean abouslue error, which is a measure of error between paired observations expressing the same phenomenon, compairson between preducted vs observed  )- \n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "# now we want to fit the model \n",
    "# epochs refers to the number of runs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1ed3d0d51d0d9fc84e9feca67a2c96385eab8afcf16092b40709d9c6021dc22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
