{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets learn using a larger model\n",
    "\n",
    "- in general we are going to be dealing with larger datasets \n",
    "- lets use the public medical cost data set     \n",
    "- import the medical cost data set from kaggle   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import keras   \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
    "insurance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Now lets define the independent and independent variables:\n",
    "- independent variable = (age, sex, bmi, children smoker region)\n",
    "- dependent variable = charges \n",
    "- teh first step we need to do is get the data ready \n",
    "- do we need to pass in different data types for different layers or differnet neurons \n",
    "- notice we whave numerical and non numerical data types ( object) in the data \n",
    "- we need to convert these data types into float32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0       yes\n",
       " 1        no\n",
       " 2        no\n",
       " 3        no\n",
       " 4        no\n",
       "        ... \n",
       " 1333     no\n",
       " 1334     no\n",
       " 1335     no\n",
       " 1336     no\n",
       " 1337    yes\n",
       " Name: smoker, Length: 1338, dtype: object,\n",
       " 0       19\n",
       " 1       18\n",
       " 2       28\n",
       " 3       33\n",
       " 4       32\n",
       "         ..\n",
       " 1333    50\n",
       " 1334    18\n",
       " 1335    18\n",
       " 1336    21\n",
       " 1337    61\n",
       " Name: age, Length: 1338, dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the data type of the different columns \n",
    "insurance[\"smoker\"] , insurance[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
       "0   19  27.900         0  16884.92400           1         0          0   \n",
       "1   18  33.770         1   1725.55230           0         1          1   \n",
       "2   28  33.000         3   4449.46200           0         1          1   \n",
       "3   33  22.705         0  21984.47061           0         1          1   \n",
       "4   32  28.880         0   3866.85520           0         1          1   \n",
       "\n",
       "   smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
       "0           1                 0                 0                 0   \n",
       "1           0                 0                 0                 1   \n",
       "2           0                 0                 0                 1   \n",
       "3           0                 0                 1                 0   \n",
       "4           0                 0                 1                 0   \n",
       "\n",
       "   region_southwest  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to encode the non numerical varibales into a numerical form. \n",
    "# lets use one-hot encoding to encode this    \n",
    "# this has to be done for all the \n",
    "# sex_df = pd.DataFrame(insurance[\"sex\"])\n",
    "# pd.get_dummies(df['sex'], prefix= ['male', 'female'])\n",
    "insurance_one_hot = pd.get_dummies(insurance)\n",
    "insurance_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0   19  27.900         0           1         0          0           1   \n",
       "1   18  33.770         1           0         1          1           0   \n",
       "2   28  33.000         3           0         1          1           0   \n",
       "3   33  22.705         0           0         1          1           0   \n",
       "4   32  28.880         0           0         1          1           0   \n",
       "\n",
       "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                 0                 0                 0                 1  \n",
       "1                 0                 0                 1                 0  \n",
       "2                 0                 0                 1                 0  \n",
       "3                 0                 1                 0                 0  \n",
       "4                 0                 1                 0                 0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create x and y values \n",
    "# first lets make X \n",
    "# since X is the training set of data we are going to need to seperate \n",
    "\n",
    "X = insurance_one_hot.drop(\"charges\", axis = 1) # the .drop funciton enables you to remove one of the columns \n",
    "y = insurance_one_hot[\"charges\"] # just getting charges by itself as the y variable\n",
    "X.head()\n",
    "# we ahve dropped charges because it is our dependent variable so we are going to need "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16884.92400\n",
       "1     1725.55230\n",
       "2     4449.46200\n",
       "3    21984.47061\n",
       "4     3866.85520\n",
       "Name: charges, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets view y \n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 1070, 268)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not lets create a training and test sets \n",
    "# if we have a feature matrix with labled vectors we can use the scikitlearn trainign test split \n",
    "from sklearn.model_selection import train_test_split \n",
    "# this is where we are going to do the 80, 20 split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X ,y, test_size = 0.20, random_state = 42) # if we dont use random state then teh split will be random so we ahve to set the split \n",
    "len(X), len(X_train), len(X_test)\n",
    "# now we have a 80/20 split \n",
    "# the number origionally in X, then the number that has been \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>46</td>\n",
       "      <td>19.950</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>47</td>\n",
       "      <td>24.320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>52</td>\n",
       "      <td>24.860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>39</td>\n",
       "      <td>34.320</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>54</td>\n",
       "      <td>21.470</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>18</td>\n",
       "      <td>31.350</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>39</td>\n",
       "      <td>23.870</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>58</td>\n",
       "      <td>25.175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>37</td>\n",
       "      <td>47.600</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>55</td>\n",
       "      <td>29.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1070 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "560    46  19.950         2           1         0          1           0   \n",
       "1285   47  24.320         0           1         0          1           0   \n",
       "1142   52  24.860         0           1         0          1           0   \n",
       "969    39  34.320         5           1         0          1           0   \n",
       "486    54  21.470         3           1         0          1           0   \n",
       "...   ...     ...       ...         ...       ...        ...         ...   \n",
       "1095   18  31.350         4           1         0          1           0   \n",
       "1130   39  23.870         5           1         0          1           0   \n",
       "1294   58  25.175         0           0         1          1           0   \n",
       "860    37  47.600         2           1         0          0           1   \n",
       "1126   55  29.900         0           0         1          1           0   \n",
       "\n",
       "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "560                  0                 1                 0                 0  \n",
       "1285                 1                 0                 0                 0  \n",
       "1142                 0                 0                 1                 0  \n",
       "969                  0                 0                 1                 0  \n",
       "486                  0                 1                 0                 0  \n",
       "...                ...               ...               ...               ...  \n",
       "1095                 1                 0                 0                 0  \n",
       "1130                 0                 0                 1                 0  \n",
       "1294                 1                 0                 0                 0  \n",
       "860                  0                 0                 0                 1  \n",
       "1126                 0                 0                 0                 1  \n",
       "\n",
       "[1070 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets see what the samples of the sets are like \n",
    "X_train\n",
    "# notice how all teh indexes are randomly shuffled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>45</td>\n",
       "      <td>25.175</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>36</td>\n",
       "      <td>30.020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>64</td>\n",
       "      <td>26.885</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>46</td>\n",
       "      <td>25.745</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>19</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>63</td>\n",
       "      <td>35.090</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>58</td>\n",
       "      <td>27.170</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>38</td>\n",
       "      <td>28.025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>54</td>\n",
       "      <td>47.410</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>51</td>\n",
       "      <td>34.200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "764    45  25.175         2           1         0          1           0   \n",
       "887    36  30.020         0           1         0          1           0   \n",
       "890    64  26.885         0           1         0          0           1   \n",
       "1293   46  25.745         3           0         1          1           0   \n",
       "259    19  31.920         0           0         1          0           1   \n",
       "...   ...     ...       ...         ...       ...        ...         ...   \n",
       "109    63  35.090         0           0         1          0           1   \n",
       "575    58  27.170         0           1         0          1           0   \n",
       "535    38  28.025         1           0         1          1           0   \n",
       "543    54  47.410         0           1         0          0           1   \n",
       "846    51  34.200         1           1         0          1           0   \n",
       "\n",
       "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "764                  1                 0                 0                 0  \n",
       "887                  0                 1                 0                 0  \n",
       "890                  0                 1                 0                 0  \n",
       "1293                 0                 1                 0                 0  \n",
       "259                  0                 1                 0                 0  \n",
       "...                ...               ...               ...               ...  \n",
       "109                  0                 0                 1                 0  \n",
       "575                  0                 1                 0                 0  \n",
       "535                  1                 0                 0                 0  \n",
       "543                  0                 0                 1                 0  \n",
       "846                  0                 0                 0                 1  \n",
       "\n",
       "[268 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8637.1006 - mae: 8637.1006\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7886.7769 - mae: 7886.7769\n",
      "Epoch 3/100\n",
      " 1/34 [..............................] - ETA: 0s - loss: 7614.6641 - mae: 7614.6641"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-03 02:17:54.299996: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 7558.1470 - mae: 7558.1470\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7792.0229 - mae: 7792.0229\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7748.3877 - mae: 7748.3877\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7595.3950 - mae: 7595.3950\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7589.9839 - mae: 7589.9839\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7698.5596 - mae: 7698.5596\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7496.7783 - mae: 7496.7783\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7493.1743 - mae: 7493.1743\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7769.7314 - mae: 7769.7314\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7706.9053 - mae: 7706.9053\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7687.7227 - mae: 7687.7227\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7689.8999 - mae: 7689.8999\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7393.5327 - mae: 7393.5327\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7780.6978 - mae: 7780.6978\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7578.5117 - mae: 7578.5117\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7750.8359 - mae: 7750.8359\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7739.2158 - mae: 7739.2158\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7875.0654 - mae: 7875.0654\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7466.6772 - mae: 7466.6772\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7941.2319 - mae: 7941.2319\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7640.2729 - mae: 7640.2729\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7539.2676 - mae: 7539.2676\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7619.9663 - mae: 7619.9663\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7644.1704 - mae: 7644.1704\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7709.0376 - mae: 7709.0376\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7366.8657 - mae: 7366.8657\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7444.3154 - mae: 7444.3154\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7616.4087 - mae: 7616.4087\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7686.3853 - mae: 7686.3853\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7548.0996 - mae: 7548.0996\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7501.5537 - mae: 7501.5537\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7363.4165 - mae: 7363.4165\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7295.4473 - mae: 7295.4473\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7569.8818 - mae: 7569.8818\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7548.2007 - mae: 7548.2007\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7424.3979 - mae: 7424.3979\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7529.7734 - mae: 7529.7734\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7467.3237 - mae: 7467.3237\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7635.9292 - mae: 7635.9292\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7536.8394 - mae: 7536.8394\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7616.5850 - mae: 7616.5850\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7439.4941 - mae: 7439.4941\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7538.0156 - mae: 7538.0156\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7415.1470 - mae: 7415.1470\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7420.6938 - mae: 7420.6938\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7509.9844 - mae: 7509.9844\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7541.1133 - mae: 7541.1133\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7467.8638 - mae: 7467.8638\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7389.3560 - mae: 7389.3560\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7499.7754 - mae: 7499.7754\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7523.9282 - mae: 7523.9282\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7243.3120 - mae: 7243.3120\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7429.5869 - mae: 7429.5869\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7313.4009 - mae: 7313.4009\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7526.3887 - mae: 7526.3887\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7542.2676 - mae: 7542.2676\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7576.9272 - mae: 7576.9272\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7546.4048 - mae: 7546.4048\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7351.2280 - mae: 7351.2280\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7302.1440 - mae: 7302.1440\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7393.0884 - mae: 7393.0884\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7442.2886 - mae: 7442.2886\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7492.6792 - mae: 7492.6792\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7561.9170 - mae: 7561.9170\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7340.5142 - mae: 7340.5142\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7496.0850 - mae: 7496.0850\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7617.0317 - mae: 7617.0317\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7641.1948 - mae: 7641.1948\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7084.2749 - mae: 7084.2749\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7240.4912 - mae: 7240.4912\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7283.4888 - mae: 7283.4888\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7335.5083 - mae: 7335.5083\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7275.6396 - mae: 7275.6396\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7313.1860 - mae: 7313.1860\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7485.7603 - mae: 7485.7603\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7352.2803 - mae: 7352.2803\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7520.5718 - mae: 7520.5718\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7279.3779 - mae: 7279.3779\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7273.8472 - mae: 7273.8472\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7176.5215 - mae: 7176.5215\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7425.6299 - mae: 7425.6299\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7403.1294 - mae: 7403.1294\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7356.0078 - mae: 7356.0078\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7484.7261 - mae: 7484.7261\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7217.6079 - mae: 7217.6079\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7261.0000 - mae: 7261.0000\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7134.1562 - mae: 7134.1562\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7083.4360 - mae: 7083.4360\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7254.1782 - mae: 7254.1782\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7268.7456 - mae: 7268.7456\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7470.5225 - mae: 7470.5225\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7210.9536 - mae: 7210.9536\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7395.6816 - mae: 7395.6816\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7328.0879 - mae: 7328.0879\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7230.4385 - mae: 7230.4385\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7261.3945 - mae: 7261.3945\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7342.5679 - mae: 7342.5679\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7106.1714 - mae: 7106.1714\n"
     ]
    }
   ],
   "source": [
    "# lets see if we can increase our current model by increaseing teh epochs to 100 \n",
    "tf.random.set_seed(42)\n",
    "# lets create a model using teh sequenctial API\n",
    "insurance_model= tf.keras.Sequential([ #groups a linear stack of layers into a tf.keras.Model.\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    ]) # this is basically saying that we want to generate a model from keras \n",
    "# now we want to compule the model \n",
    "insurance_model.compile(loss=tf.keras.losses.mae, # mae measn mean abouslue error, which is a measure of error between paired observations expressing the same phenomenon, compairson between preducted vs observed  )- \n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "# now we want to fit the model \n",
    "with tf.device('/cpu:0'): insurance_model.fit(X_train, y_train, epochs=100) # we need to use the with cup or the kernal will crash\n",
    "# epochs refers to the number of runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 11, 10)            20        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 11, 1)             11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "insurance_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 21:13:22.197566: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 8ms/step - loss: 8921.2812 - mae: 8921.2812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8921.28125, 8921.28125]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12508.2109 - mae: 12508.2109\n",
      "Epoch 2/100\n",
      " 1/34 [..............................] - ETA: 0s - loss: 12073.3750 - mae: 12073.3750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-03 01:54:11.015850: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 11697.7002 - mae: 11697.7002\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11010.5703 - mae: 11010.5703\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10500.4111 - mae: 10500.4111\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10194.6299 - mae: 10194.6299\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9788.3135 - mae: 9788.3135\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9527.3320 - mae: 9527.3320\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9592.6631 - mae: 9592.6631\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 10505.7383 - mae: 10505.7383\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9887.0908 - mae: 9887.0908\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9405.9541 - mae: 9405.9541\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9492.9512 - mae: 9492.9512\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9574.8691 - mae: 9574.8691\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9808.6807 - mae: 9808.6807\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9529.3252 - mae: 9529.3252\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10302.2842 - mae: 10302.2842\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10075.8701 - mae: 10075.8701\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8969.3818 - mae: 8969.3818\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10113.8350 - mae: 10113.8350\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10467.1738 - mae: 10467.1738\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9566.5547 - mae: 9566.5547\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9919.1611 - mae: 9919.1611\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9829.9209 - mae: 9829.9209\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9638.4092 - mae: 9638.4092\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9703.6318 - mae: 9703.6318\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9866.0254 - mae: 9866.0254\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9741.8408 - mae: 9741.8408\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9081.7686 - mae: 9081.7686\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8947.2373 - mae: 8947.2373\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10089.8096 - mae: 10089.8096\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9629.3154 - mae: 9629.3154\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 11750.8369 - mae: 11750.8369\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9339.5049 - mae: 9339.5049\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10453.7979 - mae: 10453.7979\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10701.3115 - mae: 10701.3115\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9626.5801 - mae: 9626.5801\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9877.3867 - mae: 9877.3867\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11059.5625 - mae: 11059.5625\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9730.0234 - mae: 9730.0234\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9569.2256 - mae: 9569.2256\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9672.6064 - mae: 9672.6064\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9507.6592 - mae: 9507.6592\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10197.2139 - mae: 10197.2139\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9788.7109 - mae: 9788.7109\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10159.4160 - mae: 10159.4160\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9681.8047 - mae: 9681.8047\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9677.4170 - mae: 9677.4170\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8897.4355 - mae: 8897.4355\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10060.1904 - mae: 10060.1904\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10103.9102 - mae: 10103.9102\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9686.8516 - mae: 9686.8516\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9085.8350 - mae: 9085.8350\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10296.6914 - mae: 10296.6914\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9359.5156 - mae: 9359.5156\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9161.2666 - mae: 9161.2666\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 9728.4756 - mae: 9728.4756\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9482.1680 - mae: 9482.1680\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9280.1377 - mae: 9280.1377\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9959.2666 - mae: 9959.2666\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10211.3906 - mae: 10211.3906\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10732.2051 - mae: 10732.2051\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9911.6553 - mae: 9911.6553\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12145.3174 - mae: 12145.3174\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10623.4082 - mae: 10623.4082\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9530.8965 - mae: 9530.8965\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9684.8945 - mae: 9684.8945\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9632.3896 - mae: 9632.3896\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9593.6514 - mae: 9593.6514\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9403.7656 - mae: 9403.7656\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9743.2207 - mae: 9743.2207\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9444.8369 - mae: 9444.8369\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 10132.7998 - mae: 10132.7998\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9733.6299 - mae: 9733.6299\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9580.6123 - mae: 9580.6123\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9211.0977 - mae: 9211.0977\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9331.1270 - mae: 9331.1270\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9591.7197 - mae: 9591.7197\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10146.3691 - mae: 10146.3691\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 10451.5342 - mae: 10451.5342\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 11827.9766 - mae: 11827.9766\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10081.5215 - mae: 10081.5215\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 11591.1240 - mae: 11591.1240\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9941.8350 - mae: 9941.8350\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9910.2607 - mae: 9910.2607\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 10553.1777 - mae: 10553.1777\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9409.8467 - mae: 9409.8467\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9825.2207 - mae: 9825.2207\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9787.4736 - mae: 9787.4736\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9627.1211 - mae: 9627.1211\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9205.9248 - mae: 9205.9248\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 9816.7197 - mae: 9816.7197\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9056.5020 - mae: 9056.5020\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 9841.6143 - mae: 9841.6143\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9111.5928 - mae: 9111.5928\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9451.1670 - mae: 9451.1670\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9571.9336 - mae: 9571.9336\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9442.2793 - mae: 9442.2793\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9638.0156 - mae: 9638.0156\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9133.4023 - mae: 9133.4023\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9354.9746 - mae: 9354.9746\n"
     ]
    }
   ],
   "source": [
    "# lets see if we can increase our current model by increaseing teh epochs to 100 \n",
    "tf.random.set_seed(42)\n",
    "# lets create a model using teh sequenctial API\n",
    "insurance_model2= tf.keras.Sequential([ #groups a linear stack of layers into a tf.keras.Model.\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10), \n",
    "    tf.keras.layers.Dense(1)\n",
    "    ]) # this is basically saying that we want to generate a model from keras \n",
    "# now we want to compule the model \n",
    "insurance_model2.compile(loss=tf.keras.losses.mae, # mae measn mean abouslue error, which is a measure of error between paired observations expressing the same phenomenon, compairson between preducted vs observed  )- \n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "# now we want to fit the model \n",
    "with tf.device('/cpu:0'): insurance_model2.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100, verbose=1) # we need to use the with cup or the kernal will crash\n",
    "# epochs refers to the number of runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13335.7266 - mae: 13335.7266\n",
      "Epoch 2/200\n",
      " 1/34 [..............................] - ETA: 0s - loss: 13019.7949 - mae: 13019.7949"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-03 01:57:18.691604: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 13314.8389 - mae: 13314.8389\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13274.5293 - mae: 13274.5293\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13199.7256 - mae: 13199.7256\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13074.9053 - mae: 13074.9053\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12889.0273 - mae: 12889.0273\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12651.0098 - mae: 12651.0098\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12395.2959 - mae: 12395.2959\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12192.5039 - mae: 12192.5039\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12110.9834 - mae: 12110.9834\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12084.4785 - mae: 12084.4785\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12062.7061 - mae: 12062.7061\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12041.3838 - mae: 12041.3838\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12018.9814 - mae: 12018.9814\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11995.4053 - mae: 11995.4053\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11969.7061 - mae: 11969.7061\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11941.7939 - mae: 11941.7939\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11910.9727 - mae: 11910.9727\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11876.6807 - mae: 11876.6807\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11837.4248 - mae: 11837.4248\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11792.8379 - mae: 11792.8379\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11741.0898 - mae: 11741.0898\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11680.7119 - mae: 11680.7119\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11609.6074 - mae: 11609.6074\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11526.2402 - mae: 11526.2402\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11425.3311 - mae: 11425.3311\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11307.6865 - mae: 11307.6865\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11170.9912 - mae: 11170.9912\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 11014.7217 - mae: 11014.7217\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10845.9502 - mae: 10845.9502\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10668.5098 - mae: 10668.5098\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10487.0898 - mae: 10487.0898\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10302.6035 - mae: 10302.6035\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10118.2568 - mae: 10118.2568\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9925.0420 - mae: 9925.0420\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9735.6123 - mae: 9735.6123\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9549.8271 - mae: 9549.8271\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9373.5742 - mae: 9373.5742\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9211.0762 - mae: 9211.0762\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9065.4404 - mae: 9065.4404\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8934.7500 - mae: 8934.7500\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8815.2314 - mae: 8815.2314\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8708.4180 - mae: 8708.4180\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8607.6074 - mae: 8607.6074\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8536.3408 - mae: 8536.3408\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8472.2070 - mae: 8472.2070\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8432.3633 - mae: 8432.3633\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8389.9512 - mae: 8389.9512\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8362.3594 - mae: 8362.3594\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8337.7080 - mae: 8337.7080\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8322.0117 - mae: 8322.0117\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8313.5664 - mae: 8313.5664\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8296.5430 - mae: 8296.5430\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8290.0078 - mae: 8290.0078\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8287.4893 - mae: 8287.4893\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8282.9756 - mae: 8282.9756\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8280.3125 - mae: 8280.3125\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8278.3457 - mae: 8278.3457\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8278.5957 - mae: 8278.5957\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8280.3506 - mae: 8280.3506\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 8278.4854 - mae: 8278.4854\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8275.1396 - mae: 8275.1396\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 9ms/step - loss: 8275.8848 - mae: 8275.8848\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8274.5693 - mae: 8274.5693\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8274.2383 - mae: 8274.2383\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8273.5938 - mae: 8273.5938\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8276.8916 - mae: 8276.8916\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8274.4824 - mae: 8274.4824\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8274.3379 - mae: 8274.3379\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8276.9834 - mae: 8276.9834\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8275.5977 - mae: 8275.5977\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8276.0225 - mae: 8276.0225\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.3174 - mae: 8274.3174\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.6689 - mae: 8273.6689\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8273.7725 - mae: 8273.7725\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8276.3926 - mae: 8276.3926\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8273.0977 - mae: 8273.0977\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.1523 - mae: 8274.1523\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.2471 - mae: 8275.2471\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8273.0967 - mae: 8273.0967\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.0508 - mae: 8274.0508\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8275.0605 - mae: 8275.0605\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8278.9482 - mae: 8278.9482\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.3945 - mae: 8273.3945\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8277.4922 - mae: 8277.4922\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.0674 - mae: 8275.0674\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8275.9238 - mae: 8275.9238\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8273.7627 - mae: 8273.7627\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.5156 - mae: 8273.5156\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.6553 - mae: 8275.6553\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.6045 - mae: 8273.6045\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8274.7061 - mae: 8274.7061\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8274.7432 - mae: 8274.7432\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.3115 - mae: 8275.3115\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.7627 - mae: 8274.7627\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.3232 - mae: 8274.3232\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8276.7998 - mae: 8276.7998\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.8398 - mae: 8273.8398\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8274.2100 - mae: 8274.2100\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8273.7803 - mae: 8273.7803\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8276.0371 - mae: 8276.0371\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8276.0107 - mae: 8276.0107\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.7490 - mae: 8274.7490\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.5439 - mae: 8273.5439\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8273.9238 - mae: 8273.9238\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.5723 - mae: 8273.5723\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8275.7900 - mae: 8275.7900\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8279.0410 - mae: 8279.0410\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8275.1934 - mae: 8275.1934\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8276.6504 - mae: 8276.6504\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8276.3623 - mae: 8276.3623\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8273.4189 - mae: 8273.4189\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8273.8115 - mae: 8273.8115\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8273.9570 - mae: 8273.9570\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.7393 - mae: 8275.7393\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8275.4248 - mae: 8275.4248\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.4170 - mae: 8275.4170\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.6084 - mae: 8274.6084\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8276.0947 - mae: 8276.0947\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8273.6777 - mae: 8273.6777\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8273.8838 - mae: 8273.8838\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.7305 - mae: 8273.7305\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.2783 - mae: 8274.2783\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8274.0693 - mae: 8274.0693\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.3906 - mae: 8275.3906\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.5273 - mae: 8275.5273\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8274.8359 - mae: 8274.8359\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8274.5713 - mae: 8274.5713\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.0303 - mae: 8275.0303\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8274.7949 - mae: 8274.7949\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8276.9160 - mae: 8276.9160\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8276.2920 - mae: 8276.2920\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8275.0869 - mae: 8275.0869\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.4717 - mae: 8273.4717\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.8750 - mae: 8273.8750\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.7256 - mae: 8273.7256\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8274.0625 - mae: 8274.0625\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 8274.3389 - mae: 8274.3389\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.4180 - mae: 8274.4180\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.7510 - mae: 8273.7510\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.3174 - mae: 8274.3174\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8276.6084 - mae: 8276.6084\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8276.6074 - mae: 8276.6074\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8279.0664 - mae: 8279.0664\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.0762 - mae: 8275.0762\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.6494 - mae: 8275.6494\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.8691 - mae: 8275.8691\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.1914 - mae: 8275.1914\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8274.9385 - mae: 8274.9385\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.8232 - mae: 8273.8232\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8274.4326 - mae: 8274.4326\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.0430 - mae: 8274.0430\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8277.1445 - mae: 8277.1445\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 6ms/step - loss: 8276.2051 - mae: 8276.2051\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.1318 - mae: 8274.1318\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.6113 - mae: 8273.6113\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.6777 - mae: 8275.6777\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.5752 - mae: 8274.5752\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.4854 - mae: 8273.4854\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.8584 - mae: 8274.8584\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.6641 - mae: 8273.6641\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.5811 - mae: 8274.5811\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.4043 - mae: 8274.4043\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.8877 - mae: 8273.8877\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8276.5352 - mae: 8276.5352\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.6426 - mae: 8275.6426\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.4092 - mae: 8274.4092\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.2100 - mae: 8274.2100\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.6221 - mae: 8273.6221\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.2744 - mae: 8275.2744\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.4219 - mae: 8274.4219\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.2852 - mae: 8275.2852\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.9521 - mae: 8274.9521\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.4385 - mae: 8274.4385\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.7178 - mae: 8275.7178\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.7930 - mae: 8275.7930\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.1660 - mae: 8274.1660\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.2393 - mae: 8274.2393\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.1475 - mae: 8274.1475\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.6768 - mae: 8274.6768\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.4883 - mae: 8274.4883\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.7783 - mae: 8273.7783\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8274.5049 - mae: 8274.5049\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8276.8486 - mae: 8276.8486\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8276.3701 - mae: 8276.3701\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.7744 - mae: 8275.7744\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8277.0293 - mae: 8277.0293\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.4678 - mae: 8273.4678\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.0977 - mae: 8275.0977\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8276.2354 - mae: 8276.2354\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.7002 - mae: 8273.7002\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.0205 - mae: 8274.0205\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8275.5469 - mae: 8275.5469\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.5371 - mae: 8273.5371\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.7656 - mae: 8274.7656\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.9795 - mae: 8274.9795\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.9180 - mae: 8274.9180\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8274.8477 - mae: 8274.8477\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8273.7939 - mae: 8273.7939\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8277.0254 - mae: 8277.0254\n"
     ]
    }
   ],
   "source": [
    "# lets see if we can increase our current model by increaseing teh epochs to 100 \n",
    "tf.random.set_seed(42)\n",
    "# lets create a model using teh sequenctial API\n",
    "insurance_model3= tf.keras.Sequential([ #groups a linear stack of layers into a tf.keras.Model.\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10), \n",
    "    tf.keras.layers.Dense(1)\n",
    "    ]) # this is basically saying that we want to generate a model from keras \n",
    "# now we want to compule the model \n",
    "insurance_model3.compile(loss=tf.keras.losses.mae, # mae measn mean abouslue error, which is a measure of error between paired observations expressing the same phenomenon, compairson between preducted vs observed  )- \n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"mae\"])\n",
    "# now we want to fit the model \n",
    "with tf.device('/cpu:0'): history = insurance_model3.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=200, verbose=1) # we need to use the with cup or the kernal will crash\n",
    "# epochs refers to the number of runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 11ms/step - loss: 8632.2930 - mae: 8632.2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-03 01:57:41.220569: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8632.29296875, 8632.29296875]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets evaluate atainst the test data\n",
    "insurance_model3.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now lets look at the loss rate cureve , plot the loss curve hwich is also known as a loss curve \n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1ed3d0d51d0d9fc84e9feca67a2c96385eab8afcf16092b40709d9c6021dc22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
