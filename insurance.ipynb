{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets learn using a larger model\n",
    "\n",
    "- in general we are going to be dealing with larger datasets \n",
    "- lets use the public medical cost data set     \n",
    "- import the medical cost data set from kaggle   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import keras   \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
    "insurance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Now lets define the independent and independent variables:\n",
    "- independent variable = (age, sex, bmi, children smoker region)\n",
    "- dependent variable = charges \n",
    "- teh first step we need to do is get the data ready \n",
    "- do we need to pass in different data types for different layers or differnet neurons \n",
    "- notice we whave numerical and non numerical data types ( object) in the data \n",
    "- we need to convert these data types into float32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0       yes\n",
       " 1        no\n",
       " 2        no\n",
       " 3        no\n",
       " 4        no\n",
       "        ... \n",
       " 1333     no\n",
       " 1334     no\n",
       " 1335     no\n",
       " 1336     no\n",
       " 1337    yes\n",
       " Name: smoker, Length: 1338, dtype: object,\n",
       " 0       19\n",
       " 1       18\n",
       " 2       28\n",
       " 3       33\n",
       " 4       32\n",
       "         ..\n",
       " 1333    50\n",
       " 1334    18\n",
       " 1335    18\n",
       " 1336    21\n",
       " 1337    61\n",
       " Name: age, Length: 1338, dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the data type of the different columns \n",
    "insurance[\"smoker\"] , insurance[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
       "0   19  27.900         0  16884.92400           1         0          0   \n",
       "1   18  33.770         1   1725.55230           0         1          1   \n",
       "2   28  33.000         3   4449.46200           0         1          1   \n",
       "3   33  22.705         0  21984.47061           0         1          1   \n",
       "4   32  28.880         0   3866.85520           0         1          1   \n",
       "\n",
       "   smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
       "0           1                 0                 0                 0   \n",
       "1           0                 0                 0                 1   \n",
       "2           0                 0                 0                 1   \n",
       "3           0                 0                 1                 0   \n",
       "4           0                 0                 1                 0   \n",
       "\n",
       "   region_southwest  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to encode the non numerical varibales into a numerical form. \n",
    "# lets use one-hot encoding to encode this    \n",
    "# this has to be done for all the \n",
    "# sex_df = pd.DataFrame(insurance[\"sex\"])\n",
    "# pd.get_dummies(df['sex'], prefix= ['male', 'female'])\n",
    "insurance_one_hot = pd.get_dummies(insurance)\n",
    "insurance_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0   19  27.900         0           1         0          0           1   \n",
       "1   18  33.770         1           0         1          1           0   \n",
       "2   28  33.000         3           0         1          1           0   \n",
       "3   33  22.705         0           0         1          1           0   \n",
       "4   32  28.880         0           0         1          1           0   \n",
       "\n",
       "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                 0                 0                 0                 1  \n",
       "1                 0                 0                 1                 0  \n",
       "2                 0                 0                 1                 0  \n",
       "3                 0                 1                 0                 0  \n",
       "4                 0                 1                 0                 0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create x and y values \n",
    "# first lets make X \n",
    "# since X is the training set of data we are going to need to seperate \n",
    "\n",
    "X = insurance_one_hot.drop(\"charges\", axis = 1) # the .drop funciton enables you to remove one of the columns \n",
    "y = insurance_one_hot[\"charges\"] # just getting charges by itself as the y variable\n",
    "X.head()\n",
    "# we ahve dropped charges because it is our dependent variable so we are going to need "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16884.92400\n",
       "1     1725.55230\n",
       "2     4449.46200\n",
       "3    21984.47061\n",
       "4     3866.85520\n",
       "Name: charges, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets view y \n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 1070, 268)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not lets create a training and test sets \n",
    "# if we have a feature matrix with labled vectors we can use the scikitlearn trainign test split \n",
    "from sklearn.model_selection import train_test_split \n",
    "# this is where we are going to do the 80, 20 split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X ,y, test_size = 0.20, random_state = 42) # if we dont use random state then teh split will be random so we ahve to set the split \n",
    "len(X), len(X_train), len(X_test)\n",
    "# now we have a 80/20 split \n",
    "# the number origionally in X, then the number that has been \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>46</td>\n",
       "      <td>19.950</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>47</td>\n",
       "      <td>24.320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>52</td>\n",
       "      <td>24.860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>39</td>\n",
       "      <td>34.320</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>54</td>\n",
       "      <td>21.470</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>18</td>\n",
       "      <td>31.350</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>39</td>\n",
       "      <td>23.870</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>58</td>\n",
       "      <td>25.175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>37</td>\n",
       "      <td>47.600</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>55</td>\n",
       "      <td>29.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1070 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "560    46  19.950         2           1         0          1           0   \n",
       "1285   47  24.320         0           1         0          1           0   \n",
       "1142   52  24.860         0           1         0          1           0   \n",
       "969    39  34.320         5           1         0          1           0   \n",
       "486    54  21.470         3           1         0          1           0   \n",
       "...   ...     ...       ...         ...       ...        ...         ...   \n",
       "1095   18  31.350         4           1         0          1           0   \n",
       "1130   39  23.870         5           1         0          1           0   \n",
       "1294   58  25.175         0           0         1          1           0   \n",
       "860    37  47.600         2           1         0          0           1   \n",
       "1126   55  29.900         0           0         1          1           0   \n",
       "\n",
       "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "560                  0                 1                 0                 0  \n",
       "1285                 1                 0                 0                 0  \n",
       "1142                 0                 0                 1                 0  \n",
       "969                  0                 0                 1                 0  \n",
       "486                  0                 1                 0                 0  \n",
       "...                ...               ...               ...               ...  \n",
       "1095                 1                 0                 0                 0  \n",
       "1130                 0                 0                 1                 0  \n",
       "1294                 1                 0                 0                 0  \n",
       "860                  0                 0                 0                 1  \n",
       "1126                 0                 0                 0                 1  \n",
       "\n",
       "[1070 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets see what the samples of the sets are like \n",
    "X_train\n",
    "# notice how all teh indexes are randomly shuffled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>45</td>\n",
       "      <td>25.175</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>36</td>\n",
       "      <td>30.020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>64</td>\n",
       "      <td>26.885</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>46</td>\n",
       "      <td>25.745</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>19</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>63</td>\n",
       "      <td>35.090</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>58</td>\n",
       "      <td>27.170</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>38</td>\n",
       "      <td>28.025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>54</td>\n",
       "      <td>47.410</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>51</td>\n",
       "      <td>34.200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "764    45  25.175         2           1         0          1           0   \n",
       "887    36  30.020         0           1         0          1           0   \n",
       "890    64  26.885         0           1         0          0           1   \n",
       "1293   46  25.745         3           0         1          1           0   \n",
       "259    19  31.920         0           0         1          0           1   \n",
       "...   ...     ...       ...         ...       ...        ...         ...   \n",
       "109    63  35.090         0           0         1          0           1   \n",
       "575    58  27.170         0           1         0          1           0   \n",
       "535    38  28.025         1           0         1          1           0   \n",
       "543    54  47.410         0           1         0          0           1   \n",
       "846    51  34.200         1           1         0          1           0   \n",
       "\n",
       "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "764                  1                 0                 0                 0  \n",
       "887                  0                 1                 0                 0  \n",
       "890                  0                 1                 0                 0  \n",
       "1293                 0                 1                 0                 0  \n",
       "259                  0                 1                 0                 0  \n",
       "...                ...               ...               ...               ...  \n",
       "109                  0                 0                 1                 0  \n",
       "575                  0                 1                 0                 0  \n",
       "535                  1                 0                 0                 0  \n",
       "543                  0                 0                 1                 0  \n",
       "846                  0                 0                 0                 1  \n",
       "\n",
       "[268 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8637.1006 - mae: 8637.1006\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7886.7769 - mae: 7886.7769\n",
      "Epoch 3/100\n",
      " 1/34 [..............................] - ETA: 0s - loss: 7614.6641 - mae: 7614.6641"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-03 02:17:54.299996: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 7558.1470 - mae: 7558.1470\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7792.0229 - mae: 7792.0229\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7748.3877 - mae: 7748.3877\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7595.3950 - mae: 7595.3950\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7589.9839 - mae: 7589.9839\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7698.5596 - mae: 7698.5596\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7496.7783 - mae: 7496.7783\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7493.1743 - mae: 7493.1743\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7769.7314 - mae: 7769.7314\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7706.9053 - mae: 7706.9053\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7687.7227 - mae: 7687.7227\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7689.8999 - mae: 7689.8999\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7393.5327 - mae: 7393.5327\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7780.6978 - mae: 7780.6978\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7578.5117 - mae: 7578.5117\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7750.8359 - mae: 7750.8359\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7739.2158 - mae: 7739.2158\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7875.0654 - mae: 7875.0654\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7466.6772 - mae: 7466.6772\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7941.2319 - mae: 7941.2319\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7640.2729 - mae: 7640.2729\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7539.2676 - mae: 7539.2676\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 8ms/step - loss: 7619.9663 - mae: 7619.9663\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7644.1704 - mae: 7644.1704\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7709.0376 - mae: 7709.0376\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7366.8657 - mae: 7366.8657\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7444.3154 - mae: 7444.3154\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7616.4087 - mae: 7616.4087\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7686.3853 - mae: 7686.3853\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7548.0996 - mae: 7548.0996\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7501.5537 - mae: 7501.5537\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7363.4165 - mae: 7363.4165\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7295.4473 - mae: 7295.4473\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7569.8818 - mae: 7569.8818\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7548.2007 - mae: 7548.2007\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7424.3979 - mae: 7424.3979\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7529.7734 - mae: 7529.7734\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7467.3237 - mae: 7467.3237\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7635.9292 - mae: 7635.9292\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7536.8394 - mae: 7536.8394\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7616.5850 - mae: 7616.5850\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7439.4941 - mae: 7439.4941\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7538.0156 - mae: 7538.0156\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7415.1470 - mae: 7415.1470\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7420.6938 - mae: 7420.6938\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7509.9844 - mae: 7509.9844\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7541.1133 - mae: 7541.1133\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7467.8638 - mae: 7467.8638\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7389.3560 - mae: 7389.3560\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7499.7754 - mae: 7499.7754\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7523.9282 - mae: 7523.9282\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7243.3120 - mae: 7243.3120\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7429.5869 - mae: 7429.5869\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7313.4009 - mae: 7313.4009\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7526.3887 - mae: 7526.3887\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7542.2676 - mae: 7542.2676\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7576.9272 - mae: 7576.9272\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7546.4048 - mae: 7546.4048\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7351.2280 - mae: 7351.2280\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7302.1440 - mae: 7302.1440\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7393.0884 - mae: 7393.0884\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7442.2886 - mae: 7442.2886\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7492.6792 - mae: 7492.6792\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7561.9170 - mae: 7561.9170\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7340.5142 - mae: 7340.5142\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7496.0850 - mae: 7496.0850\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7617.0317 - mae: 7617.0317\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7641.1948 - mae: 7641.1948\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7084.2749 - mae: 7084.2749\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7240.4912 - mae: 7240.4912\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7283.4888 - mae: 7283.4888\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7335.5083 - mae: 7335.5083\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7275.6396 - mae: 7275.6396\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7313.1860 - mae: 7313.1860\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7485.7603 - mae: 7485.7603\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7352.2803 - mae: 7352.2803\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7520.5718 - mae: 7520.5718\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7279.3779 - mae: 7279.3779\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7273.8472 - mae: 7273.8472\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7176.5215 - mae: 7176.5215\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7425.6299 - mae: 7425.6299\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7403.1294 - mae: 7403.1294\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7356.0078 - mae: 7356.0078\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7484.7261 - mae: 7484.7261\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7217.6079 - mae: 7217.6079\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7261.0000 - mae: 7261.0000\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7134.1562 - mae: 7134.1562\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7083.4360 - mae: 7083.4360\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7254.1782 - mae: 7254.1782\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7268.7456 - mae: 7268.7456\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7470.5225 - mae: 7470.5225\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7210.9536 - mae: 7210.9536\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7395.6816 - mae: 7395.6816\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7328.0879 - mae: 7328.0879\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7230.4385 - mae: 7230.4385\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7261.3945 - mae: 7261.3945\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7342.5679 - mae: 7342.5679\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7106.1714 - mae: 7106.1714\n"
     ]
    }
   ],
   "source": [
    "# lets see if we can increase our current model by increaseing teh epochs to 100 \n",
    "tf.random.set_seed(42)\n",
    "# lets create a model using teh sequenctial API\n",
    "insurance_model= tf.keras.Sequential([ #groups a linear stack of layers into a tf.keras.Model.\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    ]) # this is basically saying that we want to generate a model from keras \n",
    "# now we want to compule the model \n",
    "insurance_model.compile(loss=tf.keras.losses.mae, # mae measn mean abouslue error, which is a measure of error between paired observations expressing the same phenomenon, compairson between preducted vs observed  )- \n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "# now we want to fit the model \n",
    "with tf.device('/cpu:0'): insurance_model.fit(X_train, y_train, epochs=100) # we need to use the with cup or the kernal will crash\n",
    "# epochs refers to the number of runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 11, 10)            20        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 11, 1)             11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "insurance_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 21:13:22.197566: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 8ms/step - loss: 8921.2812 - mae: 8921.2812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8921.28125, 8921.28125]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13273.1602 - mae: 13273.1602\n",
      "Epoch 2/100\n",
      "20/34 [================>.............] - ETA: 0s - loss: 12595.3262 - mae: 12595.3262"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-03 02:22:16.079833: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 13104.4297 - mae: 13104.4297\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12749.5410 - mae: 12749.5410\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 12055.7500 - mae: 12055.7500\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 7ms/step - loss: 10905.8154 - mae: 10905.8154\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9457.7227 - mae: 9457.7227\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8147.6543 - mae: 8147.6543\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7528.8408 - mae: 7528.8408\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7429.1528 - mae: 7429.1528\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7409.0811 - mae: 7409.0811\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7390.8042 - mae: 7390.8042\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7368.9170 - mae: 7368.9170\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7348.5190 - mae: 7348.5190\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7326.4893 - mae: 7326.4893\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7307.5815 - mae: 7307.5815\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7285.7734 - mae: 7285.7734\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7265.7104 - mae: 7265.7104\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7242.5493 - mae: 7242.5493\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7220.5068 - mae: 7220.5068\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7197.1978 - mae: 7197.1978\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7179.0195 - mae: 7179.0195\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7151.2104 - mae: 7151.2104\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7126.4639 - mae: 7126.4639\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7101.9199 - mae: 7101.9199\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7084.3379 - mae: 7084.3379\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7052.3296 - mae: 7052.3296\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7024.3511 - mae: 7024.3511\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6996.6963 - mae: 6996.6963\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6969.0112 - mae: 6969.0112\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6942.1899 - mae: 6942.1899\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6911.7280 - mae: 6911.7280\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6884.0205 - mae: 6884.0205\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6853.4648 - mae: 6853.4648\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6823.0674 - mae: 6823.0674\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6789.6855 - mae: 6789.6855\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6755.7646 - mae: 6755.7646\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6720.2026 - mae: 6720.2026\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6689.7163 - mae: 6689.7163\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6652.4614 - mae: 6652.4614\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6618.1011 - mae: 6618.1011\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6585.8633 - mae: 6585.8633\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6559.4961 - mae: 6559.4961\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6530.0439 - mae: 6530.0439\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6506.8071 - mae: 6506.8071\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6493.5718 - mae: 6493.5718\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6475.9258 - mae: 6475.9258\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6458.8979 - mae: 6458.8979\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6445.1494 - mae: 6445.1494\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6430.9639 - mae: 6430.9639\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6417.7510 - mae: 6417.7510\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6403.2754 - mae: 6403.2754\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6392.4141 - mae: 6392.4141\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6378.7451 - mae: 6378.7451\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6364.9131 - mae: 6364.9131\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6351.5273 - mae: 6351.5273\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6337.6606 - mae: 6337.6606\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6324.8369 - mae: 6324.8369\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6310.1948 - mae: 6310.1948\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6295.6035 - mae: 6295.6035\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6284.8696 - mae: 6284.8696\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6265.6411 - mae: 6265.6411\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6253.0103 - mae: 6253.0103\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6234.9292 - mae: 6234.9292\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6218.0430 - mae: 6218.0430\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6201.1899 - mae: 6201.1899\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6183.9590 - mae: 6183.9590\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6171.2998 - mae: 6171.2998\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6148.8403 - mae: 6148.8403\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6132.5981 - mae: 6132.5981\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6112.3848 - mae: 6112.3848\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6092.7207 - mae: 6092.7207\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 6073.7422 - mae: 6073.7422\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6059.4883 - mae: 6059.4883\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6031.3853 - mae: 6031.3853\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6010.3350 - mae: 6010.3350\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5995.2178 - mae: 5995.2178\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5963.0723 - mae: 5963.0723\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5940.0610 - mae: 5940.0610\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5915.1064 - mae: 5915.1064\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5887.9990 - mae: 5887.9990\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5861.6987 - mae: 5861.6987\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5834.3066 - mae: 5834.3066\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5805.8242 - mae: 5805.8242\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5772.3232 - mae: 5772.3232\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5745.1514 - mae: 5745.1514\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5711.3481 - mae: 5711.3481\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5674.5215 - mae: 5674.5215\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5639.4927 - mae: 5639.4927\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5600.6660 - mae: 5600.6660\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5559.4326 - mae: 5559.4326\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5523.6187 - mae: 5523.6187\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5474.1250 - mae: 5474.1250\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5432.2661 - mae: 5432.2661\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5386.0527 - mae: 5386.0527\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5333.1812 - mae: 5333.1812\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5288.8159 - mae: 5288.8159\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5234.6792 - mae: 5234.6792\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5170.9360 - mae: 5170.9360\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5112.9443 - mae: 5112.9443\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5059.8447 - mae: 5059.8447\n"
     ]
    }
   ],
   "source": [
    "# lets see if we can increase our current model by increaseing teh epochs to 100 \n",
    "tf.random.set_seed(42)\n",
    "# lets create a model using teh sequenctial API\n",
    "insurance_model2= tf.keras.Sequential([ #groups a linear stack of layers into a tf.keras.Model.\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10), \n",
    "    tf.keras.layers.Dense(1)\n",
    "    ]) # this is basically saying that we want to generate a model from keras \n",
    "# now we want to compule the model \n",
    "insurance_model2.compile(loss=tf.keras.losses.mae, # mae measn mean abouslue error, which is a measure of error between paired observations expressing the same phenomenon, compairson between preducted vs observed  )- \n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"mae\"])\n",
    "# now we want to fit the model \n",
    "with tf.device('/cpu:0'): history1 = insurance_model2.fit(X_train, y_train, epochs=100)# we need to use the with cup or the kernal will crash\n",
    "# epochs refers to the number of runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13273.1602 - mae: 13273.1602\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 13104.4297 - mae: 13104.4297\n",
      "Epoch 3/200\n",
      " 1/34 [..............................] - ETA: 0s - loss: 12323.3457 - mae: 12323.3457"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 20:41:36.867616: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 12749.5410 - mae: 12749.5410\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12055.7500 - mae: 12055.7500\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10905.8154 - mae: 10905.8154\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9457.7227 - mae: 9457.7227\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8147.6543 - mae: 8147.6543\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7528.8408 - mae: 7528.8408\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7429.1528 - mae: 7429.1528\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7409.0811 - mae: 7409.0811\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7390.8042 - mae: 7390.8042\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7368.9170 - mae: 7368.9170\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7348.5190 - mae: 7348.5190\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7326.4893 - mae: 7326.4893\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7307.5815 - mae: 7307.5815\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7285.7734 - mae: 7285.7734\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7265.7104 - mae: 7265.7104\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7242.5493 - mae: 7242.5493\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7220.5068 - mae: 7220.5068\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7197.1978 - mae: 7197.1978\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7179.0195 - mae: 7179.0195\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7151.2104 - mae: 7151.2104\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7126.4639 - mae: 7126.4639\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7101.9199 - mae: 7101.9199\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7084.3379 - mae: 7084.3379\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7052.3296 - mae: 7052.3296\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7024.3511 - mae: 7024.3511\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6996.6963 - mae: 6996.6963\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6969.0112 - mae: 6969.0112\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6942.1899 - mae: 6942.1899\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6911.7280 - mae: 6911.7280\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6884.0205 - mae: 6884.0205\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6853.4648 - mae: 6853.4648\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6823.0674 - mae: 6823.0674\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6789.6855 - mae: 6789.6855\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6755.7646 - mae: 6755.7646\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6720.2026 - mae: 6720.2026\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6689.7163 - mae: 6689.7163\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6652.4614 - mae: 6652.4614\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6618.1011 - mae: 6618.1011\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6585.8633 - mae: 6585.8633\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6559.4961 - mae: 6559.4961\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6530.0439 - mae: 6530.0439\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6506.8071 - mae: 6506.8071\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6493.5718 - mae: 6493.5718\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6475.9258 - mae: 6475.9258\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6458.8979 - mae: 6458.8979\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6445.1494 - mae: 6445.1494\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6430.9639 - mae: 6430.9639\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6417.7510 - mae: 6417.7510\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6403.2754 - mae: 6403.2754\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6392.4141 - mae: 6392.4141\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6378.7451 - mae: 6378.7451\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6364.9131 - mae: 6364.9131\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6351.5273 - mae: 6351.5273\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6337.6606 - mae: 6337.6606\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6324.8369 - mae: 6324.8369\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6310.1948 - mae: 6310.1948\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6295.6035 - mae: 6295.6035\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6284.8696 - mae: 6284.8696\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6265.6411 - mae: 6265.6411\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6253.0103 - mae: 6253.0103\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6234.9292 - mae: 6234.9292\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6218.0430 - mae: 6218.0430\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6201.1899 - mae: 6201.1899\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6183.9590 - mae: 6183.9590\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6171.2998 - mae: 6171.2998\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6148.8403 - mae: 6148.8403\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6132.5981 - mae: 6132.5981\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6112.3848 - mae: 6112.3848\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 6092.7207 - mae: 6092.7207\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6073.7422 - mae: 6073.7422\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6059.4883 - mae: 6059.4883\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6031.3853 - mae: 6031.3853\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6010.3350 - mae: 6010.3350\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5995.2178 - mae: 5995.2178\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5963.0723 - mae: 5963.0723\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5940.0610 - mae: 5940.0610\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5915.1064 - mae: 5915.1064\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5887.9990 - mae: 5887.9990\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5861.6987 - mae: 5861.6987\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5834.3066 - mae: 5834.3066\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5805.8242 - mae: 5805.8242\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5772.3232 - mae: 5772.3232\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5745.1514 - mae: 5745.1514\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5711.3481 - mae: 5711.3481\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5674.5215 - mae: 5674.5215\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5639.4927 - mae: 5639.4927\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5600.6660 - mae: 5600.6660\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5559.4326 - mae: 5559.4326\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5523.6187 - mae: 5523.6187\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5474.1250 - mae: 5474.1250\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5432.2661 - mae: 5432.2661\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5386.0527 - mae: 5386.0527\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5333.1812 - mae: 5333.1812\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5288.8159 - mae: 5288.8159\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5234.6792 - mae: 5234.6792\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5170.9360 - mae: 5170.9360\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5112.9443 - mae: 5112.9443\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5059.8447 - mae: 5059.8447\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4987.7090 - mae: 4987.7090\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4915.4390 - mae: 4915.4390\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4847.4639 - mae: 4847.4639\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4768.1533 - mae: 4768.1533\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4683.4321 - mae: 4683.4321\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4601.1826 - mae: 4601.1826\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4513.4478 - mae: 4513.4478\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4423.2490 - mae: 4423.2490\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4339.1406 - mae: 4339.1406\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4255.4292 - mae: 4255.4292\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4173.2407 - mae: 4173.2407\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4102.3032 - mae: 4102.3032\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4028.0879 - mae: 4028.0879\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3987.8621 - mae: 3987.8621\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3945.6599 - mae: 3945.6599\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3918.2410 - mae: 3918.2410\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3897.1467 - mae: 3897.1467\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3871.5635 - mae: 3871.5635\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3852.5771 - mae: 3852.5771\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3835.2861 - mae: 3835.2861\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3829.0361 - mae: 3829.0361\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3823.3435 - mae: 3823.3435\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3814.8372 - mae: 3814.8372\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3806.4583 - mae: 3806.4583\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3795.8462 - mae: 3795.8462\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3805.0994 - mae: 3805.0994\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3797.2930 - mae: 3797.2930\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3791.3442 - mae: 3791.3442\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3801.2891 - mae: 3801.2891\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3790.9077 - mae: 3790.9077\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3781.4382 - mae: 3781.4382\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3775.3516 - mae: 3775.3516\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3770.3953 - mae: 3770.3953\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3771.6887 - mae: 3771.6887\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3767.4377 - mae: 3767.4377\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3766.6714 - mae: 3766.6714\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3775.2361 - mae: 3775.2361\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3784.4846 - mae: 3784.4846\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3761.7339 - mae: 3761.7339\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3762.1360 - mae: 3762.1360\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3763.4087 - mae: 3763.4087\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3763.5349 - mae: 3763.5349\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3754.6104 - mae: 3754.6104\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3750.8074 - mae: 3750.8074\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3751.2629 - mae: 3751.2629\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3754.6194 - mae: 3754.6194\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3751.5325 - mae: 3751.5325\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3755.4756 - mae: 3755.4756\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3743.7812 - mae: 3743.7812\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3738.6592 - mae: 3738.6592\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3741.3877 - mae: 3741.3877\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3742.3994 - mae: 3742.3994\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3742.1938 - mae: 3742.1938\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3737.1804 - mae: 3737.1804\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3738.9934 - mae: 3738.9934\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3736.1040 - mae: 3736.1040\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3732.9741 - mae: 3732.9741\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3729.8025 - mae: 3729.8025\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3726.4561 - mae: 3726.4561\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3733.5444 - mae: 3733.5444\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3728.0251 - mae: 3728.0251\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3725.0784 - mae: 3725.0784\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3722.1680 - mae: 3722.1680\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3726.4905 - mae: 3726.4905\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3717.1108 - mae: 3717.1108\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3721.8943 - mae: 3721.8943\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3720.7312 - mae: 3720.7312\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3715.3096 - mae: 3715.3096\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3714.2400 - mae: 3714.2400\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3708.1536 - mae: 3708.1536\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3707.5681 - mae: 3707.5681\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3709.5637 - mae: 3709.5637\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3705.6375 - mae: 3705.6375\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3709.1023 - mae: 3709.1023\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3712.1279 - mae: 3712.1279\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3705.9380 - mae: 3705.9380\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3700.1216 - mae: 3700.1216\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3696.2854 - mae: 3696.2854\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3704.3589 - mae: 3704.3589\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3709.2505 - mae: 3709.2505\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3695.9170 - mae: 3695.9170\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3693.5234 - mae: 3693.5234\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3692.0999 - mae: 3692.0999\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3698.8430 - mae: 3698.8430\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3694.2781 - mae: 3694.2781\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3696.6108 - mae: 3696.6108\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3689.0247 - mae: 3689.0247\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3694.2283 - mae: 3694.2283\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3683.9485 - mae: 3683.9485\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3682.8477 - mae: 3682.8477\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3699.1455 - mae: 3699.1455\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3684.8533 - mae: 3684.8533\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3675.5303 - mae: 3675.5303\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3675.5764 - mae: 3675.5764\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3673.1934 - mae: 3673.1934\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3682.2253 - mae: 3682.2253\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3666.2061 - mae: 3666.2061\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3671.8362 - mae: 3671.8362\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3680.2207 - mae: 3680.2207\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3666.9414 - mae: 3666.9414\n"
     ]
    }
   ],
   "source": [
    "# lets see if we can increase our current model by increaseing teh epochs to 100 \n",
    "tf.random.set_seed(42)\n",
    "# lets create a model using the sequenctial API\n",
    "insurance_model3= tf.keras.Sequential([ #groups a linear stack of layers into a tf.keras.Model.\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(10), \n",
    "    tf.keras.layers.Dense(1)\n",
    "    ]) # this is basically saying that we want to generate a model from keras \n",
    "# now we want to compule the model \n",
    "insurance_model3.compile(loss=tf.keras.losses.mae, # mae measn mean abouslue error, which is a measure of error between paired observations expressing the same phenomenon, compairson between preducted vs observed  )- \n",
    "               optimizer=tf.keras.optimizers.Adam(),\n",
    "               metrics=[\"mae\"])\n",
    "# now we want to fit the model \n",
    "with tf.device('/cpu:0'): history2 = insurance_model3.fit(X_train, y_train, epochs=200, verbose=1) # we need to use the with cup or the kernal will crash\n",
    "# epochs refers to the number of runs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-04 20:36:05.040240: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 6ms/step - loss: 3488.7856 - mae: 3488.7856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3488.78564453125, 3488.78564453125]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets evaluate atainst the test data\n",
    "insurance_model3.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now lets look at the loss rate cureve , plot the loss curve hwich is also known as a loss curve \n",
    "pd.DataFrame(history2.history).plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history1.history).plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "\n",
    "# how long should you train for?\n",
    "# depends on the problem that youre working on \n",
    "# in general we are able to use the early stopping callback to determine this\n",
    "# early stopping call back whicih is a tf compoenent that will stop training once it stops improving a ceratin metric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizataion\n",
    "Normalization is a technique often applied as part of data preparation for machine learning. The goal of normalization is to change the values of numeric columns in the dataset to use a common scale, without distorting differences in the ranges of values or losing information. Normalization is also required for some algorithms to model the data correctly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X[\"age\"].plot(kind = \"hist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X[\"bmi\"].plot(kind = \"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    574\n",
       "1    324\n",
       "2    240\n",
       "3    157\n",
       "4     25\n",
       "5     18\n",
       "Name: children, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"children\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling\n",
    "- There are 2 types of scaling that are used in machine learning: \n",
    "- scale (normalization)- converts all values to a values between 0 and 1 and prserves the origional distribution \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1ed3d0d51d0d9fc84e9feca67a2c96385eab8afcf16092b40709d9c6021dc22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
